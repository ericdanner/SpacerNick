{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "import shutil\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "\n",
    "\n",
    "from LAM_scripts.LAM_helpersDanner.py import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipeline1\n",
    "# This, for the most part, is the UDITAS pipeline modified to allow for REPLACE targeting. \n",
    "\n",
    "Overview:\n",
    "- Trim off the 5 nt on both sides and check for primering (how many to trim off of read 1 or two)\n",
    "- need to check for priming (make it able to check priming on Read1 or two. add missmatches. and if input is trimmed or not. pull primer from data sheet. pull primer using coordiantes and get seq downstream depending on lenght. \n",
    "- trims short amplicons for reads that go into the adapter or illumina primers\n",
    "- local align to the plasmid without the AAV seq at all\n",
    "- local align to the AAV seq without the HDR arms\n",
    "- after pulling out the reads that didn't align to AAV seq or plasmid backbone, analyze the breaks\n",
    "\n",
    "- generate table of expected amplicons (use the hdr sample and just replace seq between breaks if thats possible)\n",
    "- align agasint the reads that didn't map to AAV or plasmid backbone,\n",
    "  look at indels and quantification\n",
    "\n",
    "Test pipeline 2:\n",
    "- Trim up to the cut site. Run end-to-end across the genome. Look for expected off target translocations\n",
    "- also generally measure the frequency at which integrrations happen\n",
    "\n",
    "Questions:\n",
    "- which side is the HDR arm on? which of the two sides should i be looking for extra hdr transcripts from\n",
    "- Can I bring in some of the analysis tools from crispresso to understand the indel profiles better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Spaced_Nicking/LAM3_IL7R_PRF1\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "\n",
    "directory = '/home/eric/Data/Spaced_Nicking/LAM3_IL7R_PRF1'\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Ref_Genomes/hg38.2bit\n",
      "env: BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes\n"
     ]
    }
   ],
   "source": [
    "##########        Assign the file_genome_2bit location.     ############ \n",
    "#\n",
    "#   This is needed for pulling sequence from the referene genome by location\n",
    "#assembly = amplicon_info['genome']\n",
    "assembly = 'hg38'\n",
    "file_genome_2bit = os.path.join('/home/eric/Data/Ref_Genomes', assembly + '.2bit')\n",
    "print(file_genome_2bit)\n",
    "\n",
    "###############   BOWTIE2_INDEXES for genome alignments    ################\n",
    "#\n",
    "#check in bash: > ECHO $GENOMES_2BIT\n",
    "\n",
    "%env BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read2trim is : 24  nucleotides.\n",
      "done with sample 4.1.F N709 N501\n"
     ]
    }
   ],
   "source": [
    "########## Remove first 5 nts to remove adapter seq and spot generation sequencs  #########\n",
    "# \n",
    "#     Misha adds 5 nt's to help spot generation on Illumina on both read 1 and 2\n",
    "#    Read 1 has gene binding primer\n",
    "#    Read 2 has adapter to ligate on universal reverse seq\n",
    "\n",
    "\n",
    "                    # decide on the length to trim\n",
    "adapter_seq = 'GACTATAGGGCACGCGTGG'\n",
    "adapt_len = len(adapter_seq)\n",
    "read2trim = 5 + adapt_len\n",
    "print('read2trim is :', read2trim, ' nucleotides.')\n",
    "\n",
    "\n",
    "                  # run the trimming\n",
    "for i in range(14):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trimming_R1_R2(directory, amplicon_info, R1trim = 3, R2trim = read2trim, pipeline = 1)\n",
    "   \n",
    "    print('done with sample', amplicon_info['name'], amplicon_info['index_I1'],amplicon_info['index_I2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "\n",
    "LAM uses a anchored primer and then gets ride of the background gDNA. Then it uses a nested primer and so there should be a very clean product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is an example of the Levenshtein distance\n",
    "from fastDamerauLevenshtein import damerauLevenshtein\n",
    "damerauLevenshtein('AAGTGCCCCCTGTCTCTGCAGCTCCATGGCAGCCCGT', 'AAGTGCCCCCTGTCTCTGCAGCTCCATGGCTGCTAGA', similarity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n",
      "done with sample 24\n",
      "done with sample 25\n",
      "done with sample 26\n",
      "done with sample 27\n",
      "done with sample 28\n",
      "done with sample 29\n",
      "done with sample 30\n",
      "done with sample 31\n",
      "done with sample 32\n",
      "        sample_name    i7    i5  total_reads  reads_with_good_priming  \\\n",
      "0      PRF1_AAV_Fwd  N709  N501        76276                    73893   \n",
      "1      PRF1_AAV_Fwd  N709  N502        72150                    70646   \n",
      "2      PRF1_AAV_Fwd  N709  N504        27071                    26404   \n",
      "3   PRF1_Cas9WT_Fwd  N709  N505        86034                    83621   \n",
      "4   PRF1_Cas9WT_Fwd  N709  N506        28086                    27620   \n",
      "5   PRF1_Cas9WT_Fwd  N709  N507        71226                    69331   \n",
      "6     PRF1_D10A_Fwd  N709  N508       175474                   170590   \n",
      "7     PRF1_D10A_Fwd  N709  N510       159302                   154101   \n",
      "8     PRF1_D10A_Fwd  N710  N501        89175                    83924   \n",
      "9      PRF1_AAV_Rev  N711  N501       238362                   174099   \n",
      "10     PRF1_AAV_Rev  N711  N502        77428                    59447   \n",
      "11     PRF1_AAV_Rev  N711  N504          157                       96   \n",
      "12  PRF1_Cas9WT_Rev  N711  N505        71931                    53173   \n",
      "13  PRF1_Cas9WT_Rev  N711  N506        30068                    20178   \n",
      "14  PRF1_Cas9WT_Rev  N711  N507        93337                    75199   \n",
      "15    PRF1_D10A_Rev  N711  N508        84729                    58508   \n",
      "16    PRF1_D10A_Rev  N711  N510       347549                   257172   \n",
      "17    PRF1_D10A_Rev  N710  N508        23061                    21207   \n",
      "\n",
      "    reads_with_gene_specific_primer_misprimed  \\\n",
      "0                                        1379   \n",
      "1                                         612   \n",
      "2                                         370   \n",
      "3                                        1299   \n",
      "4                                         196   \n",
      "5                                         937   \n",
      "6                                        2555   \n",
      "7                                        2556   \n",
      "8                                        4289   \n",
      "9                                       61645   \n",
      "10                                      17020   \n",
      "11                                         35   \n",
      "12                                      17532   \n",
      "13                                       9386   \n",
      "14                                      16806   \n",
      "15                                      24867   \n",
      "16                                      85120   \n",
      "17                                       1587   \n",
      "\n",
      "    reads_with_indexing_primer_mispriming  \n",
      "0                                    1004  \n",
      "1                                     892  \n",
      "2                                     297  \n",
      "3                                    1114  \n",
      "4                                     270  \n",
      "5                                     958  \n",
      "6                                    2329  \n",
      "7                                    2645  \n",
      "8                                     962  \n",
      "9                                    2618  \n",
      "10                                    961  \n",
      "11                                     26  \n",
      "12                                   1226  \n",
      "13                                    504  \n",
      "14                                   1332  \n",
      "15                                   1354  \n",
      "16                                   5257  \n",
      "17                                    267  \n"
     ]
    }
   ],
   "source": [
    "############### GOOD PRIMING Filter ##########\n",
    "#\n",
    "#    Here we assume the NNNNN is no longer on Read1 and I used 'trimmed_R1R2() function'\n",
    "#   LAM gene specific primer on READ 1 in this case. The program only understnad checing primer 1***\n",
    "# there can be indels in the frame of the read\n",
    "# if the primer has a \n",
    "\n",
    "# make a dataframe to capture all of the priming information and put it in the 'results' folder\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','all_priming.xlsx')\n",
    "    \n",
    "## inputs for correct_priming2() function\n",
    "mismatches = 3                       # I am using the Levenshtein distance so if it is out of frame it costs 2 already\n",
    "trimmed_R1R2 = True                 #if the file has been already tri\n",
    "removePrimerPlusDownstream = False  # remove the primer/downstream seq if it is good (good for guideseq)\n",
    "exportMismatch = True               # export the file of mismatches sequences\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "\n",
    "    \n",
    "    #EVERYTHING IS CAPITAL\n",
    "    #                      \n",
    "    #                    \n",
    "    ThreePrimeEnd_seq =       'TTCCAGGGCTCCTAGACCACCCAGAGTTTCC'\n",
    "    #      Ch11:5226605:5226627                   \n",
    "    ThrePrimeEnd_primeronly = 'TTCCAGGGCTCCTAGACCAC'\n",
    "    \n",
    "    #3primer \n",
    "    FivePrimeEnd_seq =            'AAGTGCCCCCTGTCTCTGCAGCTCCATGGC'\n",
    "    #      Ch11:5227054:5227084\n",
    "    FivePrimeEnd_seq_primeronly = 'AAGTGCCCCCTGTCTCTGCAGC'\n",
    "\n",
    "    direction = amplicon_info['Direction']\n",
    "\n",
    "    if direction == 3:\n",
    "        primer_seq_plus_downstream = ThreePrimeEnd_seq\n",
    "        primer_seq = ThrePrimeEnd_primeronly\n",
    "    elif direction == 5:\n",
    "        primer_seq_plus_downstream = FivePrimeEnd_seq\n",
    "        primer_seq = FivePrimeEnd_seq_primeronly\n",
    "    \n",
    "    df_sample_results = correct_priming2(directory, amplicon_info, primer_seq, primer_seq_plus_downstream, \n",
    "                                         mismatches, trimmed_R1R2, removePrimerPlusDownstream, exportMismatch)\n",
    "    \n",
    "    #add the results to the ongoing dataframe        \n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "    print('done with sample', i)\n",
    "\n",
    "#export the final table\n",
    "results_df_all.to_excel(results_file)    \n",
    "print(results_df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_short_fastq(dir_sample, amplicon_info, direction5primer, direction3primer, adapter):\n",
    "\n",
    "    \n",
    "    direction = amplicon_info['Direction']\n",
    "\n",
    "    # Read1  This is the gene specific primering binding\n",
    "    if direction == 5:\n",
    "        gene_specific_primer = direction5primer         # this is the gene specific primer for the 5 side\n",
    "    elif direction == 3:\n",
    "        gene_specific_primer = direction3primer         # gene specific primer for the 3 side\n",
    "    rev_gene_specific_primer = reverse_complement(gene_specific_primer)\n",
    "    \n",
    "    # LAM adapter\n",
    "    adapter_rev = reverse_complement(adapter)\n",
    "    \n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    \n",
    "    file_R1 = create_filename(dir_sample, N7, N5, 'R1fastq_CorrPrime')\n",
    "    file_R2 = create_filename(dir_sample, N7, N5, 'R2fastq_CorrPrime')\n",
    "\n",
    "    file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "    file_cutadapt_report = create_filename(dir_sample, N7, N5, 'trimmed_report')\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(file_cutadapt_R1)):\n",
    "        os.mkdir(os.path.dirname(file_cutadapt_R1))\n",
    "    \n",
    "    \n",
    "    # remove adapters with cutadapt\n",
    "    #original uditas peramiter had an error -e 0.33 (but was cutting of random stuff too much)\n",
    "    # -a is hte 3' adapter for Read1\n",
    "    # -A is 3' adapter for Read2\n",
    "    # -m minium length\n",
    "    cutadapt_command = ['cutadapt',\n",
    "                        '-m', '120',\n",
    "                        '-e', '0.1',\n",
    "                        '-a', adapter_rev,\n",
    "                        '-A', rev_gene_specific_primer,\n",
    "                        '-o', file_cutadapt_R1, '-p', file_cutadapt_R2,\n",
    "                        file_R1, file_R2]\n",
    "\n",
    "    handle_cutadapt_report = open(file_cutadapt_report, 'wb')\n",
    "    subprocess.call(cutadapt_command, stdout=handle_cutadapt_report)\n",
    "    handle_cutadapt_report.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n",
      "done with sample 24\n",
      "done with sample 25\n",
      "done with sample 26\n",
      "done with sample 27\n",
      "done with sample 28\n",
      "done with sample 29\n",
      "done with sample 30\n",
      "done with sample 31\n",
      "done with sample 32\n"
     ]
    }
   ],
   "source": [
    "### TRIMMING ####\n",
    "#need to trim off the end of the short reads. This is for amplicons that were too short and have the other side on them.\n",
    "\n",
    "direction5primer = 'AAGTGCCCCCTGTCTCTGCAGC'\n",
    "direction3primer = 'TTCCAGGGCTCCTAGACCAC' \n",
    "\n",
    "adapter ='GACTATAGGGCACGCGTGG'\n",
    "\n",
    "for i in range(15,33):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trim_short_fastq(directory, amplicon_info, direction5primer, direction3primer, adapter)\n",
    "    \n",
    "    print('done with sample', i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need to make an new bowtie2 index file that includes targeting for alignment agains the whole genome so it is all in one sheet together. \n",
    "\n",
    "### Other option would be to align it to the amplicon, extract unaligned files and then align to the genome but seems cleaner this way. \n",
    "#### Ideally every sequence is unique between the targeting vector and genome.\n",
    "\n",
    "\n",
    "1. Build your fastas of interest and label .fa files.\n",
    "    1. You need fasta of hg38 or reference genome. You can pull this from downloaded bowtie indexed sampels and then use the following command to turn the index into a fasta file: bowtie2-inspect hg38 > hg38.fa   \n",
    "    2. Put all the fasta files in the same folder. Should also use the transfected plasmid\n",
    "2. index the files with bowtie\n",
    "    1. use the command bowtie2-build -f pE049,pe038_mc.fa,hg38.fa -p hg38_plus_targetvectorandplasmid\n",
    "    2. this has the -p to make it take less ram in my case.\n",
    "    3. In this case it adds the hg38 and the minicircle targeting file together\n",
    "    4. I have a Intel® Core™ i7-5500U CPU @ 2.40GHz × 4 with 15.1 GiB ram and it required about 13.8 gigs of ram and 2 hours to do a hg38+small fasta index\n",
    "    5. be sure to pay attention to the name of the new indexed file. \"hg38_plus_targetvector\" in example above. Add it to the sample_info.csv sheet. Under the tab 'genome_plus_targeting'.\n",
    "    6. you can check it indexed correcctly: bowtie2-inspect -s hg38_plus_targetvector\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the reference alingment sequences\n",
    "\n",
    "- plasmid sequence in .csv:  entire thing without HDR sequence (but with the ITRS) to map backbone integration\n",
    "- AAV: reference has entire AAV including Homology arms\n",
    "- HDR seq: The hdr reference sequence will be directly copied out ofthe .csv file and not altered.\n",
    "\n",
    "### Logic for following AAV integration\n",
    "1. Map locally to the plasmid without homology. This check for plasmid integration or ITR integration\n",
    "2. Extract out mappings. Things that don't map will be aligned to amplicons. Things that do map will be aligned to the AAV file.\n",
    "3. Align files that mapped to the plasmid to the complete AAV vector (they should contain ITR seq)\n",
    "4. Align files that did not map to the plasmid to the amplicons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N701    N5 :  N501\n",
      "sample name:  1.1.F.1    sample name:  Ctrl (#1) 5 end LAM-HTGTS\n",
      "rection type double_cut_same_chromosome_and_HDR\n"
     ]
    }
   ],
   "source": [
    "# single sample for testing (ignore this)\n",
    "\n",
    "amplicon_info = get_csv_data(directory, 0)\n",
    "print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "print('rection type', get_reaction_type(amplicon_info))\n",
    "\n",
    "create_plasmid_reference(directory, amplicon_info)\n",
    "create_AAV_reference(directory, amplicon_info)\n",
    "create_amplicon(directory, amplicon_info, file_genome_2bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N709    N5 :  N501\n",
      "sample name:  4.1.F    sample name:  PRF1_AAV_Fwd\n",
      "N7 : N709    N5 :  N502\n",
      "sample name:  4.2.F    sample name:  PRF1_AAV_Fwd\n",
      "N7 : N709    N5 :  N504\n",
      "sample name:  4.3.F    sample name:  PRF1_AAV_Fwd\n",
      "N7 : N709    N5 :  N505\n",
      "sample name:  5.1.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "N7 : N709    N5 :  N506\n",
      "sample name:  5.2.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "N7 : N709    N5 :  N507\n",
      "sample name:  5.3.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "N7 : N709    N5 :  N508\n",
      "sample name:  6.1.F    sample name:  PRF1_D10A_Fwd\n",
      "N7 : N709    N5 :  N510\n",
      "sample name:  6.2.F    sample name:  PRF1_D10A_Fwd\n",
      "N7 : N710    N5 :  N501\n",
      "sample name:  6.3.F    sample name:  PRF1_D10A_Fwd\n",
      "N7 : N711    N5 :  N501\n",
      "sample name:  4.1.R    sample name:  PRF1_AAV_Rev\n",
      "N7 : N711    N5 :  N502\n",
      "sample name:  4.2.R    sample name:  PRF1_AAV_Rev\n",
      "N7 : N711    N5 :  N504\n",
      "sample name:  4.3.R    sample name:  PRF1_AAV_Rev\n",
      "N7 : N711    N5 :  N505\n",
      "sample name:  5.1.R    sample name:  PRF1_Cas9WT_Rev\n",
      "N7 : N711    N5 :  N506\n",
      "sample name:  5.2.R    sample name:  PRF1_Cas9WT_Rev\n",
      "N7 : N711    N5 :  N507\n",
      "sample name:  5.3.R    sample name:  PRF1_Cas9WT_Rev\n",
      "N7 : N711    N5 :  N508\n",
      "sample name:  6.1.R    sample name:  PRF1_D10A_Rev\n",
      "N7 : N711    N5 :  N510\n",
      "sample name:  6.2.R    sample name:  PRF1_D10A_Rev\n",
      "N7 : N710    N5 :  N508\n",
      "sample name:  6.3.R    sample name:  PRF1_D10A_Rev\n"
     ]
    }
   ],
   "source": [
    "######## GENERATING REFERENCE SEQUENCES ###########\n",
    "#\n",
    "# MAKE SURE PLASMID DOESNT HAVE THE HDR PORTION IN IT\n",
    "# MAKE SURE AAV is entire AAV section\n",
    "# HDR should be entire sequence for reference knock-in\n",
    "\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "    print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "    get_reaction_type(amplicon_info)\n",
    "\n",
    "    create_plasmid_reference(directory, amplicon_info)\n",
    "    create_AAV_reference(directory, amplicon_info)\n",
    "    create_amplicon(directory, amplicon_info, file_genome_2bit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning reads to plasmid/AAV (local alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N709    N5 :  N501\n",
      "sample name:  4.1.F    sample name:  PRF1_AAV_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N502\n",
      "sample name:  4.2.F    sample name:  PRF1_AAV_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N504\n",
      "sample name:  4.3.F    sample name:  PRF1_AAV_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N505\n",
      "sample name:  5.1.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N506\n",
      "sample name:  5.2.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N507\n",
      "sample name:  5.3.F    sample name:  PRF1_Cas9WT_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N508\n",
      "sample name:  6.1.F    sample name:  PRF1_D10A_Fwd\n",
      "made filenames\n",
      "N7 : N709    N5 :  N510\n",
      "sample name:  6.2.F    sample name:  PRF1_D10A_Fwd\n",
      "made filenames\n",
      "N7 : N710    N5 :  N501\n",
      "sample name:  6.3.F    sample name:  PRF1_D10A_Fwd\n",
      "made filenames\n",
      "N7 : N711    N5 :  N501\n",
      "sample name:  4.1.R    sample name:  PRF1_AAV_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N502\n",
      "sample name:  4.2.R    sample name:  PRF1_AAV_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N504\n",
      "sample name:  4.3.R    sample name:  PRF1_AAV_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N505\n",
      "sample name:  5.1.R    sample name:  PRF1_Cas9WT_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N506\n",
      "sample name:  5.2.R    sample name:  PRF1_Cas9WT_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N507\n",
      "sample name:  5.3.R    sample name:  PRF1_Cas9WT_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N508\n",
      "sample name:  6.1.R    sample name:  PRF1_D10A_Rev\n",
      "made filenames\n",
      "N7 : N711    N5 :  N510\n",
      "sample name:  6.2.R    sample name:  PRF1_D10A_Rev\n",
      "made filenames\n",
      "N7 : N710    N5 :  N508\n",
      "sample name:  6.3.R    sample name:  PRF1_D10A_Rev\n",
      "made filenames\n"
     ]
    }
   ],
   "source": [
    "######## ALIGNING LOCAL TO PLASMID FILES ###########\n",
    "#\n",
    "# MAKE SURE PLASMID DOESNT HAVE THE AAV PORTION IN IT\n",
    "# MAKE SURE AAV DOESN'T HAVE HDR ARMS IN IT\n",
    "\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "    print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "    \n",
    "    align_plasmid_local(directory, amplicon_info, ncpu=12)\n",
    "    extract_reads_plasmid(directory, amplicon_info)\n",
    "    align_AAV_local(directory, amplicon_info, ncpu=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample PRF1_AAV_Fwd N709 N501\n",
      "done with sample PRF1_AAV_Fwd N709 N502\n",
      "done with sample PRF1_AAV_Fwd N709 N504\n",
      "done with sample PRF1_Cas9WT_Fwd N709 N505\n",
      "done with sample PRF1_Cas9WT_Fwd N709 N506\n",
      "done with sample PRF1_Cas9WT_Fwd N709 N507\n",
      "done with sample PRF1_D10A_Fwd N709 N508\n",
      "done with sample PRF1_D10A_Fwd N709 N510\n",
      "done with sample PRF1_D10A_Fwd N710 N501\n",
      "done with sample PRF1_AAV_Rev N711 N501\n",
      "done with sample PRF1_AAV_Rev N711 N502\n",
      "done with sample PRF1_AAV_Rev N711 N504\n",
      "done with sample PRF1_Cas9WT_Rev N711 N505\n",
      "done with sample PRF1_Cas9WT_Rev N711 N506\n",
      "done with sample PRF1_Cas9WT_Rev N711 N507\n",
      "done with sample PRF1_D10A_Rev N711 N508\n",
      "done with sample PRF1_D10A_Rev N711 N510\n",
      "done with sample PRF1_D10A_Rev N710 N508\n",
      "   sample_name    i7    i5  number_plasmid_alignments\n",
      "0        4.1.F  N709  N501                          0\n",
      "1        4.2.F  N709  N502                          0\n",
      "2        4.3.F  N709  N504                          0\n",
      "3        5.1.F  N709  N505                          8\n",
      "4        5.2.F  N709  N506                          8\n",
      "5        5.3.F  N709  N507                          0\n",
      "6        6.1.F  N709  N508                          9\n",
      "7        6.2.F  N709  N510                          0\n",
      "8        6.3.F  N710  N501                         38\n",
      "9        4.1.R  N711  N501                          0\n",
      "10       4.2.R  N711  N502                          0\n",
      "11       4.3.R  N711  N504                          0\n",
      "12       5.1.R  N711  N505                         83\n",
      "13       5.2.R  N711  N506                         60\n",
      "14       5.3.R  N711  N507                        467\n",
      "15       6.1.R  N711  N508                        100\n",
      "16       6.2.R  N711  N510                        932\n",
      "17       6.3.R  N710  N508                         22\n"
     ]
    }
   ],
   "source": [
    "######## QUANTIFYING PLASMID/AAV INTEGRATION ###########\n",
    "#\n",
    "\n",
    "\n",
    "#SUMMARY FILE\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','plasmid_AAV_integration.xlsx')\n",
    "\n",
    "\n",
    "# FUNCTION INPUTS\n",
    "analysis = 'plasmid'\n",
    "min_MAPQ = 1\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i) #cas9 cutting sample\n",
    "\n",
    "    df_sample_results = analyze_local_alignments(directory, amplicon_info, min_MAPQ, analysis)\n",
    "\n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "    print('done with sample', amplicon_info['description'], amplicon_info['index_I1'],amplicon_info['index_I2'])\n",
    "\n",
    "#export the final table\n",
    "results_df_all.to_excel(results_file)   \n",
    "\n",
    "print(results_df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#\n",
    "# Aligns reads globally to amplicon. \"end-to-end\" as the default function in bowtie2\n",
    "# Input: directory to be analyzed\n",
    "#        amplicon_info, slice of sample_info.csv for the sample being processed\n",
    "#        file_genome_2bit, 2bit file with the reference genome being used\n",
    "#\n",
    "#        paired = True or False\n",
    "# ##########################\n",
    "def align_ampliconLAM(dir_sample, amplicon_info, check_plasmid_insertions, paired, ncpu=4):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    has_plasmid = type(amplicon_info['plasmid_sequence']) is str or type(amplicon_info['plasmid_sequence']) is unicode\n",
    "\n",
    "    if check_plasmid_insertions == 1 and has_plasmid:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastqgz')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastqgz')\n",
    "    else:\n",
    "        file_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "        file_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1)):\n",
    "        os.mkdir(os.path.dirname(file_R1))\n",
    "\n",
    "    file_sam_amplicons = create_filename(dir_sample, N7, N5, 'sam_amplicons')\n",
    "    file_sam_report_amplicons = create_filename(dir_sample, N7, N5, 'sam_report_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_sam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_sam_amplicons))\n",
    "\n",
    "    file_bam_amplicons = create_filename(dir_sample, N7, N5, 'bam_amplicons')\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_bam_amplicons)):\n",
    "        os.mkdir(os.path.dirname(file_bam_amplicons))\n",
    "\n",
    "    # global alignment to the amplicons with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "    \n",
    "    if paired == True:\n",
    "        bowtie2_command = ['bowtie2', '-p', str(ncpu), '--very-sensitive', \n",
    "                           '-X', '5000', '-k', '3', '-x', 'amplicons',\n",
    "                           '-1', file_R1, '-2', file_R2,\n",
    "                           '-S', file_sam_amplicons]\n",
    "    \n",
    "    else:\n",
    "        bowtie2_command = ['bowtie2', '--very-sensitive', '-p', str(ncpu),\n",
    "                   '-X', '5000', '-k', '3', '-x', 'amplicons',\n",
    "                   '-U', file_R1, '-S', file_sam_amplicons]\n",
    "\n",
    "\n",
    "    handle_sam_report_amplicons = open(file_sam_report_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_amplicons)\n",
    "\n",
    "    handle_sam_report_amplicons.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_amplicons_command = ['samtools', 'view', '-Sb', file_sam_amplicons]\n",
    "\n",
    "    handle_file_bam_amplicons = open(file_bam_amplicons, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_amplicons_command, stdout=handle_file_bam_amplicons)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_amplicons_command = ['samtools', 'sort', file_bam_amplicons, '-o', file_sorted_bam_amplicons]\n",
    "\n",
    "    subprocess.call(sort_bam_amplicons_command)\n",
    "\n",
    "    # Clean up\n",
    "    #os.remove(file_sam_amplicons)\n",
    "    os.remove(file_bam_amplicons)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_amplicons_index_command = ['samtools', 'index', file_sorted_bam_amplicons]\n",
    "    subprocess.call(create_bam_amplicons_index_command)\n",
    "\n",
    "    os.chdir(initial_dir)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align filtered reads to amplicons (end-to-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Aligning reads to amplicons ###########\n",
    "#\n",
    "# \n",
    "#  This will go thorugh and align the amplicons. \n",
    "# check_plamid_insertions is if the aligned reads should come from plasmid integration removed fastq\n",
    "# paired, do you use paired ends for alignment or just Read1 (gene specific primer)\n",
    "\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i) \n",
    "    align_ampliconLAM(directory, amplicon_info, check_plasmid_insertions = True, paired = True, ncpu = 14)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to extract all unmapped reads to the amplicons\n",
    "# reads, 'single', 'paired'\n",
    "################################################################################\n",
    "#  THIS IS USED FOR PIPELINE 2 WHERE WE ALIGN THEM TO THE REST OF HTE GENOME\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)    \n",
    "    extract_unmapped_reads_amplicons_LAM(directory, amplicon_info, 'paired')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the aligned amplicon reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allreads is :  81118\n",
      "HDRcount is :  107\n",
      "done with sample 15 PRF1_AAV_Fwd N709 N501\n",
      "Allreads is :  88978\n",
      "HDRcount is :  21\n",
      "done with sample 16 PRF1_AAV_Fwd N709 N502\n",
      "Allreads is :  24351\n",
      "HDRcount is :  2\n",
      "done with sample 17 PRF1_AAV_Fwd N709 N504\n",
      "Allreads is :  61089\n",
      "HDRcount is :  18200\n",
      "done with sample 18 PRF1_Cas9WT_Fwd N709 N505\n",
      "Allreads is :  25100\n",
      "HDRcount is :  7843\n",
      "done with sample 19 PRF1_Cas9WT_Fwd N709 N506\n",
      "Allreads is :  61315\n",
      "HDRcount is :  27293\n",
      "done with sample 20 PRF1_Cas9WT_Fwd N709 N507\n",
      "Allreads is :  192399\n",
      "HDRcount is :  111275\n",
      "done with sample 21 PRF1_D10A_Fwd N709 N508\n",
      "Allreads is :  175210\n",
      "HDRcount is :  102913\n",
      "done with sample 22 PRF1_D10A_Fwd N709 N510\n",
      "Allreads is :  98606\n",
      "HDRcount is :  50975\n",
      "done with sample 23 PRF1_D10A_Fwd N710 N501\n",
      "Allreads is :  209460\n",
      "HDRcount is :  127\n",
      "done with sample 24 PRF1_AAV_Rev N711 N501\n",
      "Allreads is :  77189\n",
      "HDRcount is :  58\n",
      "done with sample 25 PRF1_AAV_Rev N711 N502\n",
      "Allreads is :  131\n",
      "HDRcount is :  0\n",
      "done with sample 26 PRF1_AAV_Rev N711 N504\n",
      "Allreads is :  75736\n",
      "HDRcount is :  1892\n",
      "done with sample 27 PRF1_Cas9WT_Rev N711 N505\n",
      "Allreads is :  27674\n",
      "HDRcount is :  727\n",
      "done with sample 28 PRF1_Cas9WT_Rev N711 N506\n",
      "Allreads is :  113758\n",
      "HDRcount is :  2356\n",
      "done with sample 29 PRF1_Cas9WT_Rev N711 N507\n",
      "Allreads is :  41825\n",
      "HDRcount is :  10250\n",
      "done with sample 30 PRF1_D10A_Rev N711 N508\n",
      "Allreads is :  192437\n",
      "HDRcount is :  43587\n",
      "done with sample 31 PRF1_D10A_Rev N711 N510\n",
      "Allreads is :  24572\n",
      "HDRcount is :  2685\n",
      "done with sample 32 PRF1_D10A_Rev N710 N508\n",
      "   sample_name    i7    i5  sample_descript  Total_mapped_reads  \\\n",
      "0        4.1.F  N709  N501     PRF1_AAV_Fwd               81118   \n",
      "1        4.2.F  N709  N502     PRF1_AAV_Fwd               88978   \n",
      "2        4.3.F  N709  N504     PRF1_AAV_Fwd               24351   \n",
      "3        5.1.F  N709  N505  PRF1_Cas9WT_Fwd               61089   \n",
      "4        5.2.F  N709  N506  PRF1_Cas9WT_Fwd               25100   \n",
      "5        5.3.F  N709  N507  PRF1_Cas9WT_Fwd               61315   \n",
      "6        6.1.F  N709  N508    PRF1_D10A_Fwd              192399   \n",
      "7        6.2.F  N709  N510    PRF1_D10A_Fwd              175210   \n",
      "8        6.3.F  N710  N501    PRF1_D10A_Fwd               98606   \n",
      "9        4.1.R  N711  N501     PRF1_AAV_Rev              209460   \n",
      "10       4.2.R  N711  N502     PRF1_AAV_Rev               77189   \n",
      "11       4.3.R  N711  N504     PRF1_AAV_Rev                 131   \n",
      "12       5.1.R  N711  N505  PRF1_Cas9WT_Rev               75736   \n",
      "13       5.2.R  N711  N506  PRF1_Cas9WT_Rev               27674   \n",
      "14       5.3.R  N711  N507  PRF1_Cas9WT_Rev              113758   \n",
      "15       6.1.R  N711  N508    PRF1_D10A_Rev               41825   \n",
      "16       6.2.R  N711  N510    PRF1_D10A_Rev              192437   \n",
      "17       6.3.R  N710  N508    PRF1_D10A_Rev               24572   \n",
      "\n",
      "    wt_cut1_total_reads  wt_cut1_total_indels  wt_cut1_total_deletions  \\\n",
      "0                   830                     0                        0   \n",
      "1                   748                     0                        0   \n",
      "2                    11                     0                        0   \n",
      "3                   208                   178                      159   \n",
      "4                     4                     0                        0   \n",
      "5                   108                    77                       74   \n",
      "6                  1102                    35                        6   \n",
      "7                   908                    27                       12   \n",
      "8                   584                    28                       16   \n",
      "9                104574                    19                       17   \n",
      "10                38533                    12                       11   \n",
      "11                   65                     0                        0   \n",
      "12                 4259                  3190                     2683   \n",
      "13                 1518                   644                      220   \n",
      "14                 4942                  3866                     2628   \n",
      "15                12606                  1193                     1181   \n",
      "16                51761                  4812                     4598   \n",
      "17                 8453                   662                      623   \n",
      "\n",
      "    wt_cut1_total_insertions  wt_cut2_total_reads  ...  \\\n",
      "0                          0                20088  ...   \n",
      "1                          0                22214  ...   \n",
      "2                          0                 7521  ...   \n",
      "3                         19                 2114  ...   \n",
      "4                          0                 1498  ...   \n",
      "5                          3                 2770  ...   \n",
      "6                         29                19633  ...   \n",
      "7                         17                17834  ...   \n",
      "8                         13                11671  ...   \n",
      "9                          2                39297  ...   \n",
      "10                         1                13727  ...   \n",
      "11                         0                   28  ...   \n",
      "12                       507                 1430  ...   \n",
      "13                       424                  758  ...   \n",
      "14                      1239                 1863  ...   \n",
      "15                        12                 3570  ...   \n",
      "16                       220                12525  ...   \n",
      "17                        40                 2147  ...   \n",
      "\n",
      "    1a_1a_cut1_total_reads  1a_1a_cut1_total_indels  \\\n",
      "0                        0                        0   \n",
      "1                        0                        0   \n",
      "2                        0                        0   \n",
      "3                        0                        0   \n",
      "4                        0                        0   \n",
      "5                        0                        0   \n",
      "6                        0                        0   \n",
      "7                        0                        0   \n",
      "8                        0                        0   \n",
      "9                        0                        0   \n",
      "10                       0                        0   \n",
      "11                       0                        0   \n",
      "12                       0                        0   \n",
      "13                       0                        0   \n",
      "14                       0                        0   \n",
      "15                       0                        0   \n",
      "16                       0                        0   \n",
      "17                       0                        0   \n",
      "\n",
      "    1a_1a_cut1_total_deletions  1a_1a_cut1_total_insertions  \\\n",
      "0                            0                            0   \n",
      "1                            0                            0   \n",
      "2                            0                            0   \n",
      "3                            0                            0   \n",
      "4                            0                            0   \n",
      "5                            0                            0   \n",
      "6                            0                            0   \n",
      "7                            0                            0   \n",
      "8                            0                            0   \n",
      "9                            0                            0   \n",
      "10                           0                            0   \n",
      "11                           0                            0   \n",
      "12                           0                            0   \n",
      "13                           0                            0   \n",
      "14                           0                            0   \n",
      "15                           0                            0   \n",
      "16                           0                            0   \n",
      "17                           0                            0   \n",
      "\n",
      "    2b_2b_cut1_total_reads  2b_2b_cut1_total_indels  \\\n",
      "0                       87                       87   \n",
      "1                       94                       94   \n",
      "2                       55                       55   \n",
      "3                       22                       22   \n",
      "4                       13                       13   \n",
      "5                        6                        6   \n",
      "6                      112                      105   \n",
      "7                      120                      120   \n",
      "8                       64                       64   \n",
      "9                        0                        0   \n",
      "10                       0                        0   \n",
      "11                       0                        0   \n",
      "12                       0                        0   \n",
      "13                       0                        0   \n",
      "14                       0                        0   \n",
      "15                       0                        0   \n",
      "16                       0                        0   \n",
      "17                       0                        0   \n",
      "\n",
      "    2b_2b_cut1_total_deletions  2b_2b_cut1_total_insertions  HDR_total_reads  \\\n",
      "0                           86                            1              107   \n",
      "1                           90                            4               21   \n",
      "2                           50                            5                2   \n",
      "3                            3                           19            18200   \n",
      "4                            0                           13             7843   \n",
      "5                            6                            0            27293   \n",
      "6                          101                            4           111275   \n",
      "7                           95                           27           102913   \n",
      "8                           60                            4            50975   \n",
      "9                            0                            0              127   \n",
      "10                           0                            0               58   \n",
      "11                           0                            0                0   \n",
      "12                           0                            0             1892   \n",
      "13                           0                            0              727   \n",
      "14                           0                            0             2356   \n",
      "15                           0                            0            10250   \n",
      "16                           0                            0            43587   \n",
      "17                           0                            0             2685   \n",
      "\n",
      "    median_fragment_size  \n",
      "0                  434.0  \n",
      "1                  435.0  \n",
      "2                  399.0  \n",
      "3                  390.0  \n",
      "4                  400.0  \n",
      "5                  418.0  \n",
      "6                  399.0  \n",
      "7                  389.0  \n",
      "8                  403.0  \n",
      "9                  345.0  \n",
      "10                 354.0  \n",
      "11                 363.5  \n",
      "12                 364.0  \n",
      "13                 325.0  \n",
      "14                 352.0  \n",
      "15                 242.0  \n",
      "16                 254.0  \n",
      "17                 368.0  \n",
      "\n",
      "[18 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "################### ANALYZING THE ALIGNMENTS ###############\n",
    "#\n",
    "#          INDELS AND QUANTIFICATION\n",
    "\n",
    "\n",
    "#SUMMARY FILE\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','all_amplicon_counts.xlsx')\n",
    "\n",
    "# function inputs\n",
    "window_size = 15\n",
    "amplicon_window_around_cut = 1000\n",
    "min_MAPQ = 5\n",
    "min_AS = -180\n",
    "\n",
    "for i in range(15,33):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)    \n",
    "\n",
    "    result_amplicon_df = analyze_alignments_LAM(directory, amplicon_info, window_size, amplicon_window_around_cut, min_MAPQ, min_AS)\n",
    "\n",
    "    \n",
    "    results_df_all = results_df_all.append(result_amplicon_df, ignore_index=True)\n",
    "    print('done with sample', i, amplicon_info['description'], amplicon_info['index_I1'],amplicon_info['index_I2'])\n",
    "\n",
    "\n",
    "results_df_all.to_excel(results_file)   \n",
    "\n",
    "print(results_df_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE 2. TRIM TO THE CUTSITE AND THEN ALIGN AGAINST THE GENOME\n",
    "\n",
    "Do end-to-end alignments of all the reads map to the region of interest? I want to see what that region looks like blown up    \n",
    "\n",
    "i will only use primer 1 to keep things simpler for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIMMING OFF TO CUTSITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Function to extract all unmapped reads to the amplicons\n",
    "# reads, 'single', 'paired'\n",
    "################################################################################\n",
    "def extract_unmapped_reads_amplicons_LAM(dir_sample, amplicon_info, reads):\n",
    "\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "\n",
    "    file_sorted_bam_amplicons = create_filename(dir_sample, N7, N5, 'sorted_bam_amplicons')\n",
    "\n",
    "    file_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'unmapped_bam_amplicons')\n",
    "\n",
    "    file_qsorted_unmapped_bam_amplicons = create_filename(dir_sample, N7, N5, 'qsorted_unmapped_bam_amplicons')\n",
    "\n",
    "    file_R1_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R1fastq')\n",
    "    file_R2_unmapped = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_R2fastq')\n",
    "    file_unmapped_report = create_filename(dir_sample, N7, N5, 'unmapped_amplicons_report')\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(file_R1_unmapped)):\n",
    "        os.mkdir(os.path.dirname(file_R1_unmapped))\n",
    "\n",
    "    extract_unmapped_bam_command = ['samtools', 'view', '-b', '-f', '0x4', file_sorted_bam_amplicons, '-o',\n",
    "                                    file_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(extract_unmapped_bam_command)\n",
    "\n",
    "    qsort_unmapped_bam_command = ['samtools', 'sort', '-n', file_unmapped_bam_amplicons, '-o',\n",
    "                                  file_qsorted_unmapped_bam_amplicons]\n",
    "\n",
    "    subprocess.call(qsort_unmapped_bam_command)\n",
    "\n",
    "    if reads == 'paired':\n",
    "        bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_amplicons,\n",
    "                              '-fq', file_R1_unmapped, '-fq2', file_R2_unmapped]\n",
    "\n",
    "        handle_unmapped_report = open(file_unmapped_report, 'wb')\n",
    "        subprocess.call(bamtofastq_command, stderr=handle_unmapped_report)\n",
    "\n",
    "        for fo in [file_R1_unmapped, file_R2_unmapped]:\n",
    "            with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "                f_out.writelines(f_in)\n",
    "            os.remove(fo)\n",
    "    elif reads == 'single':\n",
    "        bamtofastq_command = ['bedtools', 'bamtofastq', '-i', file_qsorted_unmapped_bam_amplicons,\n",
    "                              '-fq', file_R1_unmapped]\n",
    "\n",
    "        handle_unmapped_report = open(file_unmapped_report, 'wb')\n",
    "        subprocess.call(bamtofastq_command, stderr=handle_unmapped_report)\n",
    "\n",
    "        for fo in [file_R1_unmapped]:\n",
    "            with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "                f_out.writelines(f_in)\n",
    "            os.remove(fo)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
