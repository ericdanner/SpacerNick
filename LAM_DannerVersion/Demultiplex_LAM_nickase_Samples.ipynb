{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if I need these but they were in the uditas software\n",
    "class Error(Exception):\n",
    "    \"\"\"Base class for exceptions in this module.\"\"\"\n",
    "    pass\n",
    "\n",
    "class StrandError(Error):\n",
    "    \"\"\"Exception raised for errors in the strand information.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class ReactionTypeError(Error):\n",
    "    \"\"\"Exception raised for errors in the reaction type to be processed.\n",
    "    Attributes:\n",
    "        expression -- input expression in which the error occurred\n",
    "        message -- explanation of the error\n",
    "    \"\"\"\n",
    "    def __init__(self, message):\n",
    "        self.message = message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are copied and unchanged from the Uditas v1 software\n",
    "\n",
    "################################################################################\n",
    "# Open .fastq or .fastq.gz files for reading\n",
    "################################################################################\n",
    "def open_fastq_or_gz(filename):\n",
    "    if filename.endswith(\".fastq\") and os.access(filename, os.F_OK):\n",
    "        return open(filename, \"rU\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename, os.F_OK):\n",
    "        return gzip.open(filename, \"rb\")\n",
    "    elif filename.endswith(\".fastq\") and os.access(filename + \".gz\", os.F_OK):\n",
    "        return gzip.open(filename + \".gz\", \"rb\")\n",
    "    elif filename.endswith(\".fastq.gz\") and os.access(filename[:-3], os.F_OK):\n",
    "        return open(filename[:-3], \"rU\")\n",
    "    raise IOError(\"Unknown file: \" + filename)\n",
    "\n",
    "################################################################################\n",
    "# Hamming distance\n",
    "# From http://code.activestate.com/recipes/499304-hamming-distance/\n",
    "################################################################################\n",
    "def hamm_dist(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    ne = operator.ne\n",
    "    return sum(itertools.imap(ne, str1, str2))\n",
    "\n",
    "################################################################################\n",
    "# Select closest barcode with a maximum number of mismatches\n",
    "# By default it returns barcodes with a maximum of n_max_mismatches=2 mismatches\n",
    "################################################################################\n",
    "def select_barcode(seq, barcode_list, n_max_mismatches=1):\n",
    "    # This compares with all barcodes and selects the one with the smallest hamming distance\n",
    "    # Before calling this function check if the sequence is already a barcode\n",
    "    matched_barcodes = list()\n",
    "    distances = list()\n",
    "    for barcode in barcode_list:\n",
    "        h_d = hamm_dist(seq, barcode)\n",
    "        if h_d <= n_max_mismatches:\n",
    "            matched_barcodes.append(barcode)\n",
    "            distances.append(h_d)\n",
    "    indices = [i for i, x in enumerate(distances) if x == min(distances)]\n",
    "    return [matched_barcodes[i] for i in indices]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Mask sequence by quality score\n",
    "################################################################################\n",
    "def mask(seq, qual, min_qual=12):\n",
    "\n",
    "    return \"\".join((b if (ord(q) - 33) >= min_qual else \"N\") for b, q in itertools.izip(seq, qual))\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# get the reverse-complement DNA sequence\n",
    "################################################################################\n",
    "def reverse_complement(seq):\n",
    "    seq_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'N': 'N', 'a': 't', 't': 'a', 'g': 'c', 'c': 'g'}\n",
    "    return \"\".join([seq_dict[base] for base in reversed(seq)])\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Create umi dict\n",
    "################################################################################\n",
    "def create_umi_dict(filename):\n",
    "\n",
    "    umi_file = open_fastq_or_gz(filename)\n",
    "\n",
    "    umi_dict = dict()\n",
    "\n",
    "    umi_reads = itertools.izip(umi_file)\n",
    "\n",
    "    for header_umi in umi_reads:\n",
    "\n",
    "        seq_umi = umi_reads.next()\n",
    "        umi_reads.next()\n",
    "        qual_umi = umi_reads.next()\n",
    "        umi_dict[header_umi[0].split()[0][1:]] = [seq_umi[0].rstrip(), qual_umi[0].rstrip()]\n",
    "\n",
    "    return umi_dict\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# create list of output files\n",
    "################################################################################\n",
    "def create_filename(dir_sample, N7, N5, filetype):\n",
    "    main_folder = os.path.join(dir_sample, N7 + '_' + N5)\n",
    "    if filetype == 'mainfolder':\n",
    "        return main_folder\n",
    "    elif filetype == 'amplicons':\n",
    "        return os.path.join(main_folder, 'amplicons')\n",
    "    elif filetype == 'R1fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq')\n",
    "    elif filetype == 'R1fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq.gz')\n",
    "    elif filetype == 'R2fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq')\n",
    "    elif filetype == 'R2fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq.gz')\n",
    "    elif filetype == 'umifastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq')\n",
    "    elif filetype == 'umifastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_umi.fastq.gz')\n",
    "    elif filetype == 'R1trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R1.trimmed.fastq.gz')\n",
    "    elif filetype == 'R2trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R2.trimmed.fastq.gz')\n",
    "    elif filetype == 'trimmed_report':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '.trimmed.report.txt')\n",
    "    elif filetype == 'sam_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'sam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_qsorted_unmapped.bam')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'sam_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_amplicons_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_qsorted_amplicons_unmapped.bam')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_report':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '.unmapped.report.txt')\n",
    "    elif filetype == 'sam_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'results_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5)  # We will append the window size later\n",
    "    elif filetype == 'results_plasmid':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_plasmid.xlsx')\n",
    "    elif filetype == 'results_all_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_all_amplicons.xlsx')\n",
    "    elif filetype == 'results_genomewide':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_genomewide.xlsx')\n",
    "    elif filetype == 'summary_all_alignments':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_summary_all_alignments.xlsx')\n",
    "    elif filetype == 'read_counts':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_read_counts.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N701', 'N702', 'N703', 'N704', 'N705', 'N706'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_i1_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is changed from the uditas software. They had the index2 read before UMI but ours is UMI->Index2 \n",
    "#so the function was tweaked accordingly\n",
    "\n",
    "############################\n",
    "#\n",
    "# Demultiplexer\n",
    "# Input: folder to demultiplex, with Undetermined fastq files and sample info in sample_info.csv\n",
    "#\n",
    "# ##########################\n",
    "def demultiplex_no_UMIs(dir_sample):\n",
    "\n",
    "    # Read indices\n",
    "    sample_info_filename = os.path.join(dir_sample, 'sample_info.csv')\n",
    "\n",
    "    experiments = pd.read_csv(sample_info_filename)\n",
    "\n",
    "    #this is what uditas has but my files are named different after BCL2FASTQ conv\n",
    "    '''\n",
    "    r1_fastq = os.path.join(dir_sample, 'Undetermined_S0_L001_R1_001.fastq.gz')\n",
    "    r2_fastq = os.path.join(dir_sample, 'Undetermined_S0_L001_R2_001.fastq.gz')\n",
    "    i1_fastq = os.path.join(dir_sample, 'Undetermined_S0_L001_I1_001.fastq.gz')\n",
    "    i2_fastq = os.path.join(dir_sample, 'Undetermined_S0_L001_I2_001.fastq.gz')\n",
    "    '''\n",
    "    #names of my files\n",
    "    r1_fastq = os.path.join(dir_sample, 'Undetermined_S0_R1_001.fastq.gz')\n",
    "    r2_fastq = os.path.join(dir_sample, 'Undetermined_S0_R2_001.fastq.gz')\n",
    "    i1_fastq = os.path.join(dir_sample, 'Undetermined_S0_I1_001.fastq.gz')\n",
    "    i2_fastq = os.path.join(dir_sample, 'Undetermined_S0_I2_001.fastq.gz')\n",
    "\n",
    "    index_i1_list = list(experiments['index_I1'])\n",
    "    barcode_i1_list = list(experiments['barcode_I1'])\n",
    "    i1_dict = dict(zip(barcode_i1_list, index_i1_list))\n",
    "    index_i2_list = list(experiments['index_I2'])\n",
    "    barcode_i2_list = list(experiments['barcode_I2'])\n",
    "    i2_dict = dict(zip(barcode_i2_list, index_i2_list))\n",
    "\n",
    "    \n",
    "    index_i1_set = set(index_i1_list)\n",
    "\n",
    "    good_barcode_pairs = dict()\n",
    "\n",
    "    \n",
    "    for bc in index_i1_set:\n",
    "        good_barcode_pairs[bc] = list(experiments.loc[bc == experiments['index_I1']]['index_I2'])\n",
    "\n",
    "    barcode_i2_length = len(barcode_i2_list[0])\n",
    "\n",
    "    files_out = list()\n",
    "\n",
    "    # Create all directories if necessary\n",
    "    N7_N5 = itertools.izip(index_i1_list, index_i2_list)\n",
    "    for (N7, N5) in N7_N5:\n",
    "        exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "        if not os.path.exists(exp_dir):\n",
    "            os.mkdir(exp_dir)\n",
    "        if not os.path.exists(os.path.dirname(create_filename(dir_sample, N7, N5, 'R1fastq'))):\n",
    "            os.mkdir(os.path.dirname(create_filename(dir_sample, N7, N5, 'R1fastq')))\n",
    "        files_out.append(create_filename(dir_sample, N7, N5, 'R1fastq'))\n",
    "        files_out.append(create_filename(dir_sample, N7, N5, 'R2fastq'))\n",
    "\n",
    "    # create dict of output basename files, to map to opened files\n",
    "    n_file = 0\n",
    "    files_out_dict = dict()\n",
    "\n",
    "    for file_selected in files_out:\n",
    "        files_out_dict[os.path.basename(file_selected)] = n_file\n",
    "        n_file += 1\n",
    "\n",
    "    if not os.path.exists(os.path.join(dir_sample, 'mismatched')):\n",
    "        os.mkdir(os.path.join(dir_sample, 'mismatched'))\n",
    "\n",
    "    if not os.path.exists(os.path.join(dir_sample, 'reports')):\n",
    "        os.mkdir(os.path.join(dir_sample, 'reports'))\n",
    "\n",
    "    file_out_not_in_exp_list_r1 = os.path.join(dir_sample, 'mismatched', 'not_in_exp_list_R1.fastq')\n",
    "    file_out_not_in_exp_list_r2 = os.path.join(dir_sample, 'mismatched', 'not_in_exp_list_R2.fastq')\n",
    "    file_out_not_in_exp_list_i1 = os.path.join(dir_sample, 'mismatched', 'not_in_exp_list_I1.fastq')\n",
    "    file_out_not_in_exp_list_i2 = os.path.join(dir_sample, 'mismatched', 'not_in_exp_list_I2.fastq')\n",
    "\n",
    "    file_out_mismatched_adapters_r1 = os.path.join(dir_sample, 'mismatched', 'mismatched_adapters_R1.fastq')\n",
    "    file_out_mismatched_adapters_r2 = os.path.join(dir_sample, 'mismatched', 'mismatched_adapters_R2.fastq')\n",
    "    file_out_mismatched_adapters_i1 = os.path.join(dir_sample, 'mismatched', 'mismatched_adapters_I1.fastq')\n",
    "    file_out_mismatched_adapters_i2 = os.path.join(dir_sample, 'mismatched', 'mismatched_adapters_I2.fastq')\n",
    "\n",
    "    # We open all output files\n",
    "    ref_files = [open(filename, \"w\") for filename in files_out]\n",
    "\n",
    "    ref_file_out_not_in_exp_list_r1 = open(file_out_not_in_exp_list_r1, \"w\")\n",
    "    ref_file_out_not_in_exp_list_r2 = open(file_out_not_in_exp_list_r2, \"w\")\n",
    "    ref_file_out_not_in_exp_list_i1 = open(file_out_not_in_exp_list_i1, \"w\")\n",
    "    ref_file_out_not_in_exp_list_i2 = open(file_out_not_in_exp_list_i2, \"w\")\n",
    "\n",
    "    ref_file_out_mismatched_adapters_r1 = open(file_out_mismatched_adapters_r1, \"w\")\n",
    "    ref_file_out_mismatched_adapters_r2 = open(file_out_mismatched_adapters_r2, \"w\")\n",
    "    ref_file_out_mismatched_adapters_i1 = open(file_out_mismatched_adapters_i1, \"w\")\n",
    "    ref_file_out_mismatched_adapters_i2 = open(file_out_mismatched_adapters_i2, \"w\")\n",
    "\n",
    "    file_read_counts = [0] * len(files_out)\n",
    "\n",
    "    # We open r1,r2,i1,i2 files and distribute reads\n",
    "    with open_fastq_or_gz(r1_fastq) as r1_file, open_fastq_or_gz(r2_fastq) as r2_file, open_fastq_or_gz(i1_fastq) as i1_file, open_fastq_or_gz(i2_fastq) as i2_file:\n",
    "        # Add counters for all reads\n",
    "\n",
    "        reads_in_experiment_list_count = 0\n",
    "\n",
    "        reads_not_in_experiment_list_count = 0\n",
    "\n",
    "        mismatch_count = 0\n",
    "        mismatch_count_i1 = 0\n",
    "        mismatch_count_i2 = 0\n",
    "\n",
    "        mismatch_dict_i1 = dict()\n",
    "        mismatch_dict_i2 = dict()\n",
    "\n",
    "        r1_r2_i1_i2 = itertools.izip(r1_file, r2_file, i1_file, i2_file)\n",
    "\n",
    "        for header_r1, header_r2, header_i1, header_i2 in r1_r2_i1_i2:\n",
    "    \n",
    "            seq_r1, seq_r2, seq_i1, seq_i2 = r1_r2_i1_i2.next()\n",
    "\n",
    "            r1_r2_i1_i2.next()\n",
    "\n",
    "            qual_r1, qual_r2, qual_i1, qual_i2 = r1_r2_i1_i2.next()\n",
    "\n",
    "            seq_i1, seq_i2 = seq_i1.rstrip(), seq_i2.rstrip()\n",
    "\n",
    "            qual_i1, qual_i2 = qual_i1.rstrip(), qual_i2.rstrip()\n",
    "\n",
    "            #We mask with N any bases with scores below or equal to , (11, default in mask)\n",
    "            #I sequenced using miniseq with the original Uditas so my index2 read was UMI->Index. So I have to reverse the original script which was Index->Umi\n",
    "            seq_i1 = mask(seq_i1, qual_i1)\n",
    "            seq_i2 = mask(seq_i2, qual_i2)\n",
    "\n",
    "            \n",
    "            '''\n",
    "            #this is the original Uditas where the Index2->UMI ordering\n",
    "            seq_i2 = mask(seq_i2_plus_umi[:barcode_i2_length], qual_i2_plus_umi[:barcode_i2_length])\n",
    "            umi_qual = qual_i2_plus_umi[barcode_i2_length:]\n",
    "            umi = mask(seq_i2_plus_umi[barcode_i2_length:], umi_qual)\n",
    "            '''\n",
    "            \n",
    "            # change to 1 for reads with perfect indices or match after correction\n",
    "            is_good_index = 0\n",
    "\n",
    "            if (seq_i1 in barcode_i1_list) and (seq_i2 in barcode_i2_list):\n",
    "                # perfect match case\n",
    "                is_good_index = 1\n",
    "            else:\n",
    "                # We look for barcodes with up to two mismatches, default in select_barcode\n",
    "                seq_i1_match = select_barcode(seq_i1, barcode_i1_list)\n",
    "                seq_i2_match = select_barcode(seq_i2, barcode_i2_list)\n",
    "                if len(seq_i2_match) > 0 and len(seq_i1_match) > 0:\n",
    "                    # match after selecting adapter with up to 2 mismatches (default in select_barcode)\n",
    "                    is_good_index = 1\n",
    "                    seq_i1 = seq_i1_match[0]\n",
    "                    seq_i2 = seq_i2_match[0]\n",
    "\n",
    "            if is_good_index:\n",
    "                # We test whether the read has on of the combination of indices from our experiment list\n",
    "                # If not save in a separate file\n",
    "                if i2_dict[seq_i2] in good_barcode_pairs[i1_dict[seq_i1]]:\n",
    "\n",
    "                    r1f = create_filename(dir_sample, i1_dict[seq_i1], i2_dict[seq_i2], 'R1fastq')\n",
    "                    r2f = create_filename(dir_sample, i1_dict[seq_i1], i2_dict[seq_i2], 'R2fastq')\n",
    "\n",
    "                    print(\"\\n\".join([header_r1.rstrip(), seq_r1.rstrip(), \"+\", qual_r1.rstrip()]),\n",
    "                          file=ref_files[files_out_dict[os.path.basename(r1f)]])\n",
    "                    file_read_counts[files_out_dict[os.path.basename(r1f)]] += 1\n",
    "\n",
    "                    print(\"\\n\".join([header_r2.rstrip(), seq_r2.rstrip(), \"+\", qual_r2.rstrip()]),\n",
    "                          file=ref_files[files_out_dict[os.path.basename(r2f)]])\n",
    "                    file_read_counts[files_out_dict[os.path.basename(r2f)]] += 1\n",
    "\n",
    "                    reads_in_experiment_list_count += 1\n",
    "\n",
    "                else:\n",
    "                    # We print reads with mismatched labels to our experiments\n",
    "                    print(\"\\n\".join([header_r1.rstrip(), seq_r1.rstrip(), \"+\", qual_r1.rstrip()]),\n",
    "                          file=ref_file_out_not_in_exp_list_r1)\n",
    "                    print(\"\\n\".join([header_r2.rstrip(), seq_r2.rstrip(), \"+\", qual_r2.rstrip()]),\n",
    "                          file=ref_file_out_not_in_exp_list_r2)\n",
    "                    print(\"\\n\".join([header_i1.rstrip(), seq_i1.rstrip(), \"+\", qual_i1.rstrip()]),\n",
    "                          file=ref_file_out_not_in_exp_list_i1)\n",
    "                    print(\"\\n\".join([header_i2.rstrip(), seq_i2.rstrip(), \"+\",\n",
    "                                     qual_i2.rstrip()]), file=ref_file_out_not_in_exp_list_i2)\n",
    "\n",
    "                    reads_not_in_experiment_list_count += 1\n",
    "            else:\n",
    "                # We print reads with unknown/mismatched adapters\n",
    "                print(\"\\n\".join([header_r1.rstrip(), seq_r1.rstrip(), \"+\", qual_r1.rstrip()]),\n",
    "                      file=ref_file_out_mismatched_adapters_r1)\n",
    "                print(\"\\n\".join([header_r2.rstrip(), seq_r2.rstrip(), \"+\", qual_r2.rstrip()]),\n",
    "                      file=ref_file_out_mismatched_adapters_r2)\n",
    "                print(\"\\n\".join([header_i1.rstrip(), seq_i1.rstrip(), \"+\", qual_i1.rstrip()]),\n",
    "                      file=ref_file_out_mismatched_adapters_i1)\n",
    "                print(\"\\n\".join([header_i2.rstrip(), seq_i2.rstrip(), \"+\",\n",
    "                                 qual_i2.rstrip()]), file=ref_file_out_mismatched_adapters_i2)\n",
    "\n",
    "                if seq_i2 not in i2_dict.keys():\n",
    "                    if seq_i2 in mismatch_dict_i2.keys():\n",
    "                        mismatch_dict_i2[seq_i2] += 1\n",
    "                    else:\n",
    "                        mismatch_dict_i2[seq_i2] = 1\n",
    "                    mismatch_count_i2 += 1\n",
    "\n",
    "                if seq_i1 not in i1_dict.keys():\n",
    "                    if seq_i1 in mismatch_dict_i1.keys():\n",
    "                        mismatch_dict_i1[seq_i1] += 1\n",
    "                    else:\n",
    "                        mismatch_dict_i1[seq_i1] = 1\n",
    "                    mismatch_count_i1 += 1\n",
    "\n",
    "                mismatch_count += 1\n",
    "\n",
    "    # close all files\n",
    "    for rf in ref_files:\n",
    "        rf.close()\n",
    "\n",
    "    ref_file_out_not_in_exp_list_r1.close()\n",
    "    ref_file_out_not_in_exp_list_r2.close()\n",
    "    ref_file_out_not_in_exp_list_i1.close()\n",
    "    ref_file_out_not_in_exp_list_i2.close()\n",
    "\n",
    "    ref_file_out_mismatched_adapters_r1.close()\n",
    "    ref_file_out_mismatched_adapters_r2.close()\n",
    "    ref_file_out_mismatched_adapters_i1.close()\n",
    "    ref_file_out_mismatched_adapters_i2.close()\n",
    "\n",
    "    # print report of counts for individual files\n",
    "    report_file = os.path.join(dir_sample, 'reports', 'report_individual_files.xls')\n",
    "\n",
    "    x = np.array(file_read_counts)\n",
    "    fh = open(report_file, \"w\")\n",
    "    print(\"\\t\".join(['filename', 'reads_count']), file=fh)\n",
    "\n",
    "    for i in np.nonzero(x)[0]:\n",
    "        print(\"\\t\".join([os.path.basename(files_out[i]), str(file_read_counts[i])]), file=fh)\n",
    "    fh.close()\n",
    "\n",
    "    # print report overall counts\n",
    "    report_file = os.path.join(dir_sample, 'reports', 'report_overall.xls')\n",
    "\n",
    "    fh = open(report_file, \"w\")\n",
    "\n",
    "    print('Total number of reads:\\t' + str(reads_in_experiment_list_count + reads_not_in_experiment_list_count +\n",
    "                                           mismatch_count) + '\\n', file=fh)\n",
    "    print('Reads without I1 or I2 adapters:\\t' + str(mismatch_count) + '\\n', file=fh)\n",
    "    print('Reads without I1 adapters:\\t' + str(mismatch_count_i1) + '\\n', file=fh)\n",
    "    print('Reads without I2 adapters:\\t' + str(mismatch_count_i2) + '\\n', file=fh)\n",
    "    print('Reads with I1 or I2 adapters in the wrong combination:\\t' + str(reads_not_in_experiment_list_count) + '\\n',\n",
    "          file=fh)\n",
    "    print('Reads with I1 or I2 adapters matching our experiments:\\t' + str(reads_in_experiment_list_count) + '\\n',\n",
    "          file=fh)\n",
    "    fh.close()\n",
    "\n",
    "    # print report mismatched i1_rc adapters\n",
    "    report_file = os.path.join(dir_sample, 'reports', 'report_mismatched_adapters_i1.xls')\n",
    "\n",
    "    fh = open(report_file, \"w\")\n",
    "\n",
    "    print('I1_RC\\tCount', file=fh)\n",
    "\n",
    "    for dict_element in mismatch_dict_i1:\n",
    "        print(dict_element + '\\t' + str(mismatch_dict_i1[dict_element]), file=fh)\n",
    "\n",
    "    fh.close()\n",
    "\n",
    "    # print report mismatched i2 adapters\n",
    "    report_file = os.path.join(dir_sample, 'reports', 'report_mismatched_adapters_i2.xls')\n",
    "\n",
    "    fh = open(report_file, \"w\")\n",
    "\n",
    "    print('I2\\tCount', file=fh)\n",
    "\n",
    "    for dict_element in mismatch_dict_i2:\n",
    "        print(dict_element + '\\t' + str(mismatch_dict_i2[dict_element]), file=fh)\n",
    "\n",
    "    fh.close()\n",
    "\n",
    "    # gzip fastq files\n",
    "    for fo in files_out:\n",
    "        with open(fo) as f_in, gzip.open(fo + '.gz', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Data\n",
    "#unsorted files: /media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only\n",
    "#Take the first 1000 files (5000 lines)\n",
    "#command to view first 17 lines of files\n",
    "$head -17 filelocation_or_name\n",
    "\n",
    "#### of all 4 file types - If you do it multiple times it just appends text lines to bottom of text editor\n",
    "#(terminal)\n",
    "$head -n50000 Undetermined_S0_I1_001.fastq >> ./10000Reads/Undetermined_S0_I1_001.fastq\n",
    "$head -n50000 Undetermined_S0_I2_001.fastq >> ./10000Reads/Undetermined_S0_I2_001.fastq\n",
    "$head -n50000 Undetermined_S0_R1_001.fastq >> ./10000Reads/Undetermined_S0_R1_001.fastq\n",
    "$head -n50000 Undetermined_S0_R2_001.fastq >> ./10000Reads/Undetermined_S0_R2_001.fastq\n",
    "\n",
    "#### check how many lines: (terminal)\n",
    "$wc -l Undetermined_S0_I1_001.fastq\n",
    "\n",
    "wc -l Del_Report_Cntl.fastq\n",
    "\n",
    "$head -n4000 Del_Report_Cntl.fastq >> Del_Report_Cntl1000.fastq\n",
    "$head -n4000 Del_Report_Targeted.fastq >> Del_Report_Targeted1000.fastq\n",
    "$head -n4000 Polb_Cntl.fastq >> Polb_Cntl1000.fastq\n",
    "$head -n4000 Polb_Targeted.fastq >> Polb_Targeted1000.fastq\n",
    "\n",
    "### can compress with gZip\n",
    "$gzip Undetermined_S0_I1_001.fastq\n",
    "$gzip Undetermined_S0_I2_001.fastq\n",
    "$gzip Undetermined_S0_R1_001.fastq\n",
    "$gzip Undetermined_S0_R2_001.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only/10000Reads\n"
     ]
    }
   ],
   "source": [
    "#unsorted 10000 test files:\n",
    "# * old code *\n",
    "directory10000 = '/media/edanner/NewUbuntuSpace/Workspace/LinearAmp/Sequence2_191129_MN00157_0047_A000H2GWGF/P_Eric4_BCL2Fastq_only/10000Reads'\n",
    "print(directory10000)\n",
    "demultiplex(directory10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Spaced_Nicking/LAM2_Miniseq_ELANE\n"
     ]
    }
   ],
   "source": [
    "#test all of my files\n",
    "directory = '/home/eric/Data/Spaced_Nicking/LAM2_Miniseq_ELANE'\n",
    "\n",
    "print(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs the demultiplexing for all \n",
    "demultiplex_no_UMIs(directory)\n",
    "#took about 1.5 hr on my personal computer for an entire miniseq run demulitplexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/home/eric/Data/Spaced_Nicking/LAM3_IL7R_PRF1'\n",
    "demultiplex_no_UMIs(directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
