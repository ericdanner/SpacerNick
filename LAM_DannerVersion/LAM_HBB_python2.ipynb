{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is helpful to make a small test set of each data by taking the first 2000-4000 lines from each fasta file \n",
    "#### of all 4 file types - If you do it multiple times it just appends text lines to bottom of text editor\n",
    "\n",
    "$head -n2000 N706_N504_R1.fastq >> ./10000Reads/N706_N504_R1.fastq\n",
    "\n",
    "check how many lines: (terminal)\n",
    "\n",
    "$wc -l N706_N504_R1.fastq\n",
    "\n",
    "can compress with gZip\n",
    " \n",
    "$gzip N706_N505_R1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "import shutil\n",
    "\n",
    "from LAM_scripts.LAM_helpersDanner.py import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pipeline1\n",
    "# This, for the most part, is the UDITAS pipeline modified to allow for REPLACE targeting. \n",
    "\n",
    "Overview:\n",
    "- Trim off the 5 nt on both sides and check for primering (how many to trim off of read 1 or two)\n",
    "- need to check for priming (make it able to check priming on Read1 or two. add missmatches. and if input is trimmed or not. pull primer from data sheet. pull primer using coordiantes and get seq downstream depending on lenght. \n",
    "- trims short amplicons for reads that go into the adapter or illumina primers\n",
    "- local align to the plasmid without the AAV seq at all\n",
    "- local align to the AAV seq without the HDR arms\n",
    "- after pulling out the reads that didn't align to AAV seq or plasmid backbone, analyze the breaks\n",
    "\n",
    "- generate table of expected amplicons (use the hdr sample and just replace seq between breaks if thats possible)\n",
    "- align agasint the reads that didn't map to AAV or plasmid backbone,\n",
    "  look at indels and quantification\n",
    "\n",
    "Test pipeline 2:\n",
    "- Trim up to the cut site. Run end-to-end across the genome. Look for expected off target translocations\n",
    "- also generally measure the frequency at which integrrations happen\n",
    "\n",
    "Questions:\n",
    "- which side is the HDR arm on? which of the two sides should i be looking for extra hdr transcripts from\n",
    "- Can I bring in some of the analysis tools from crispresso to understand the indel profiles better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Spaced_Nicking/LAM_MiSeq_HBB_1/Demulitiplexed_corefacility\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "\n",
    "directory = '/home/eric/Data/Spaced_Nicking/LAM_MiSeq_HBB_1/Demulitiplexed_corefacility'\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Ref_Genomes/hg38.2bit\n",
      "env: BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes\n"
     ]
    }
   ],
   "source": [
    "##########        Assign the file_genome_2bit location.     ############ \n",
    "#\n",
    "#   This is needed for pulling sequence from the referene genome by location\n",
    "#assembly = amplicon_info['genome']\n",
    "assembly = 'hg38'\n",
    "file_genome_2bit = os.path.join('/home/eric/Data/Ref_Genomes', assembly + '.2bit')\n",
    "print(file_genome_2bit)\n",
    "\n",
    "###############   BOWTIE2_INDEXES for genome alignments    ################\n",
    "#\n",
    "#check in bash: > ECHO $GENOMES_2BIT\n",
    "\n",
    "%env BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read2trim is : 24  nucleotides.\n",
      "number of reads: 8320\n",
      "done with sample 0\n",
      "number of reads: 40781\n",
      "done with sample 1\n",
      "number of reads: 21681\n",
      "done with sample 2\n",
      "number of reads: 26980\n",
      "done with sample 3\n",
      "number of reads: 34345\n",
      "done with sample 4\n",
      "number of reads: 23382\n",
      "done with sample 5\n",
      "number of reads: 14105\n",
      "done with sample 6\n",
      "number of reads: 16620\n",
      "done with sample 7\n",
      "number of reads: 13242\n",
      "done with sample 8\n",
      "number of reads: 39568\n",
      "done with sample 9\n",
      "number of reads: 17759\n",
      "done with sample 10\n",
      "number of reads: 47438\n",
      "done with sample 11\n",
      "number of reads: 49661\n",
      "done with sample 12\n",
      "number of reads: 130634\n",
      "done with sample 13\n",
      "number of reads: 118465\n",
      "done with sample 14\n",
      "number of reads: 98215\n",
      "done with sample 15\n",
      "number of reads: 82900\n",
      "done with sample 16\n",
      "number of reads: 86032\n",
      "done with sample 17\n",
      "number of reads: 60302\n",
      "done with sample 18\n",
      "number of reads: 60363\n",
      "done with sample 19\n",
      "number of reads: 75480\n",
      "done with sample 20\n",
      "number of reads: 41911\n",
      "done with sample 21\n",
      "number of reads: 99176\n",
      "done with sample 22\n",
      "number of reads: 96247\n",
      "done with sample 23\n",
      "number of reads: 26761\n",
      "done with sample 24\n",
      "number of reads: 219128\n",
      "done with sample 25\n",
      "number of reads: 67693\n",
      "done with sample 26\n",
      "number of reads: 161655\n",
      "done with sample 27\n",
      "number of reads: 149613\n",
      "done with sample 28\n",
      "number of reads: 81483\n",
      "done with sample 29\n",
      "number of reads: 112391\n",
      "done with sample 30\n",
      "number of reads: 34368\n",
      "done with sample 31\n",
      "number of reads: 136024\n",
      "done with sample 32\n",
      "number of reads: 289817\n",
      "done with sample 33\n",
      "number of reads: 215129\n",
      "done with sample 34\n",
      "number of reads: 110614\n",
      "done with sample 35\n",
      "number of reads: 104901\n",
      "done with sample 36\n",
      "number of reads: 432414\n",
      "done with sample 37\n",
      "number of reads: 103402\n",
      "done with sample 38\n",
      "number of reads: 291850\n",
      "done with sample 39\n",
      "number of reads: 180922\n",
      "done with sample 40\n",
      "number of reads: 333190\n",
      "done with sample 41\n",
      "number of reads: 158413\n",
      "done with sample 42\n",
      "number of reads: 96349\n",
      "done with sample 43\n",
      "number of reads: 271826\n",
      "done with sample 44\n",
      "number of reads: 303748\n",
      "done with sample 45\n",
      "number of reads: 411653\n",
      "done with sample 46\n",
      "number of reads: 157638\n",
      "done with sample 47\n",
      "number of reads: 6630\n",
      "done with sample 48\n",
      "number of reads: 40364\n",
      "done with sample 49\n",
      "number of reads: 145961\n",
      "done with sample 50\n",
      "number of reads: 45518\n",
      "done with sample 51\n",
      "number of reads: 34\n",
      "done with sample 52\n",
      "number of reads: 52\n",
      "done with sample 53\n",
      "number of reads: 35\n",
      "done with sample 54\n",
      "number of reads: 26\n",
      "done with sample 55\n"
     ]
    }
   ],
   "source": [
    "########## Remove first 5 nts to remove adapter seq and spot generation sequencs  #########\n",
    "# \n",
    "#     Misha adds 5 nt's to help spot generation on Illumina on both read 1 and 2\n",
    "#    Read 1 has gene binding primer\n",
    "#    Read 2 has adapter to ligate on universal reverse seq\n",
    "\n",
    "\n",
    "                    # decide on the length to trim\n",
    "adapter_seq = 'GACTATAGGGCACGCGTGG'\n",
    "adapt_len = len(adapter_seq)\n",
    "read2trim = 5 + adapt_len\n",
    "print('read2trim is :', read2trim, ' nucleotides.')\n",
    "\n",
    "\n",
    "                  # run the trimming\n",
    "for i in range(56):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trimming_R1_R2(directory, amplicon_info, R1trim = 5, R2trim = read2trim)\n",
    "    \n",
    "    print('done with sample', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTCACAGTGCAGCTCACTCAG\n",
      "CTGAGTGAGCTGCACTGTGACA\n"
     ]
    }
   ],
   "source": [
    "#could make an automatic way to generate the primer mismatch and downstream if I want later\n",
    "start = 5226605\n",
    "end = 5226627\n",
    "\n",
    "genome = twobitreader.TwoBitFile(file_genome_2bit)\n",
    "primer = genome['chr11'][int(start):int(end)]\n",
    "print(primer)\n",
    "print(reverse_complement(primer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "\n",
    "LAM uses a anchored primer and then gets ride of the background gDNA. Then it uses a nested primer and so there should be a very clean product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n",
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n",
      "done with sample 24\n",
      "done with sample 25\n",
      "done with sample 26\n",
      "done with sample 27\n",
      "done with sample 28\n",
      "done with sample 29\n",
      "done with sample 30\n",
      "done with sample 31\n",
      "done with sample 32\n",
      "done with sample 33\n",
      "done with sample 34\n",
      "done with sample 35\n",
      "done with sample 36\n",
      "done with sample 37\n",
      "done with sample 38\n",
      "done with sample 39\n",
      "done with sample 40\n",
      "done with sample 41\n",
      "done with sample 42\n",
      "done with sample 43\n",
      "done with sample 44\n",
      "done with sample 45\n",
      "done with sample 46\n",
      "done with sample 47\n",
      "done with sample 48\n",
      "done with sample 49\n",
      "done with sample 50\n",
      "done with sample 51\n",
      "done with sample 52\n",
      "done with sample 53\n",
      "done with sample 54\n",
      "done with sample 55\n",
      "   sample_name    i7    i5  total_reads  reads_with_good_priming  \\\n",
      "0      1.1.F.1  N701  N501         8320                     8190   \n",
      "1      1.2.F.1  N701  N502        40781                    40288   \n",
      "2      1.3.F.1  N701  N504        21681                    21409   \n",
      "3      2.1.F.1  N701  N505        26980                    26678   \n",
      "4      2.2.F.1  N701  N506        34345                    33926   \n",
      "5      2.3.F.1  N701  N507        23382                    23060   \n",
      "6      3.1.F.1  N701  N508        14105                    13899   \n",
      "7      3.2.F.1  N701  N510        16620                    16397   \n",
      "8      3.3.F.1  N702  N501        13242                    13047   \n",
      "9      4.1.F.1  N702  N502        39568                    39034   \n",
      "10     4.2.F.1  N702  N504        17759                    17504   \n",
      "11     4.3.F.1  N702  N505        47438                    46787   \n",
      "12     1.1.R.1  N702  N506        49661                    49213   \n",
      "13     1.2.R.1  N702  N507       130634                   129483   \n",
      "14     1.3.R.1  N702  N508       118465                   117378   \n",
      "15     2.1.R.1  N702  N510        98215                    97318   \n",
      "16     2.2.R.1  N703  N501        82900                    82147   \n",
      "17     2.3.R.1  N703  N502        86032                    85274   \n",
      "18     3.1.R.1  N703  N504        60302                    59283   \n",
      "19     3.2.R.1  N703  N505        60363                    59566   \n",
      "20     3.3.R.1  N703  N506        75480                    74119   \n",
      "21     4.1.R.1  N703  N507        41911                    41180   \n",
      "22     4.2.R.1  N703  N508        99176                    96879   \n",
      "23     4.3.R.1  N703  N510        96247                    94474   \n",
      "24     1.1.F.2  N704  N501        26761                    26358   \n",
      "25     1.2.F.2  N704  N502       219128                   216408   \n",
      "26     1.3.F.2  N704  N504        67693                    66700   \n",
      "27     2.1.F.2  N704  N505       161655                   159086   \n",
      "28     2.2.F.2  N704  N506       149613                   147699   \n",
      "29     2.3.F.2  N704  N507        81483                    80357   \n",
      "30     3.1.F.2  N704  N508       112391                   110446   \n",
      "31     3.2.F.2  N704  N510        34368                    33892   \n",
      "32     3.3.F.2  N705  N501       136024                   133906   \n",
      "33     4.1.F.2  N705  N502       289817                   285782   \n",
      "34     4.2.F.2  N705  N504       215129                   212067   \n",
      "35     4.3.F.2  N705  N505       110614                   108992   \n",
      "36     1.1.R.2  N705  N506       104901                   103846   \n",
      "37     1.2.R.2  N705  N507       432414                   428573   \n",
      "38     1.3.R.2  N705  N508       103402                   102192   \n",
      "39     2.1.R.2  N705  N510       291850                   289134   \n",
      "40     2.2.R.2  N706  N501       180922                   179300   \n",
      "41     2.3.R.2  N706  N502       333190                   329827   \n",
      "42     3.1.R.2  N706  N504       158413                   155958   \n",
      "43     3.2.R.2  N706  N505        96349                    94814   \n",
      "44     3.3.R.2  N706  N506       271826                   266409   \n",
      "45     4.1.R.2  N706  N507       303748                   297325   \n",
      "46     4.2.R.2  N706  N508       411653                   404284   \n",
      "47     4.3.R.2  N706  N510       157638                   154074   \n",
      "48     4.2.F.3  N707  N501         6630                     6467   \n",
      "49     4.2.F.4  N707  N502        40364                    39836   \n",
      "50     4.2.R.3  N707  N504       145961                   143598   \n",
      "51     4.2.R.4  N707  N505        45518                    44664   \n",
      "52      NC.F.1  N707  N506           34                        8   \n",
      "53      NC.R.1  N707  N507           52                       38   \n",
      "54      NC.F.2  N707  N508           35                        1   \n",
      "55      NC.R.2  N707  N510           26                       23   \n",
      "\n",
      "    reads_with_gene_specific_primer_misprimed  \\\n",
      "0                                          13   \n",
      "1                                          44   \n",
      "2                                          25   \n",
      "3                                          39   \n",
      "4                                          39   \n",
      "5                                          32   \n",
      "6                                          30   \n",
      "7                                          18   \n",
      "8                                          36   \n",
      "9                                          45   \n",
      "10                                         28   \n",
      "11                                        113   \n",
      "12                                         19   \n",
      "13                                         81   \n",
      "14                                         97   \n",
      "15                                         62   \n",
      "16                                         75   \n",
      "17                                         37   \n",
      "18                                        504   \n",
      "19                                        292   \n",
      "20                                        748   \n",
      "21                                        385   \n",
      "22                                       1505   \n",
      "23                                        969   \n",
      "24                                         52   \n",
      "25                                        230   \n",
      "26                                        264   \n",
      "27                                        815   \n",
      "28                                        286   \n",
      "29                                        182   \n",
      "30                                        670   \n",
      "31                                         32   \n",
      "32                                        561   \n",
      "33                                        631   \n",
      "34                                        640   \n",
      "35                                        402   \n",
      "36                                        117   \n",
      "37                                        242   \n",
      "38                                        330   \n",
      "39                                        356   \n",
      "40                                        157   \n",
      "41                                        525   \n",
      "42                                       1146   \n",
      "43                                        689   \n",
      "44                                       3109   \n",
      "45                                       4024   \n",
      "46                                       3976   \n",
      "47                                       2303   \n",
      "48                                         81   \n",
      "49                                         60   \n",
      "50                                       1123   \n",
      "51                                        493   \n",
      "52                                          9   \n",
      "53                                          0   \n",
      "54                                          0   \n",
      "55                                          1   \n",
      "\n",
      "    reads_with_indexing_primer_mispriming  \n",
      "0                                     117  \n",
      "1                                     449  \n",
      "2                                     247  \n",
      "3                                     263  \n",
      "4                                     380  \n",
      "5                                     290  \n",
      "6                                     176  \n",
      "7                                     205  \n",
      "8                                     159  \n",
      "9                                     489  \n",
      "10                                    227  \n",
      "11                                    538  \n",
      "12                                    429  \n",
      "13                                   1070  \n",
      "14                                    990  \n",
      "15                                    835  \n",
      "16                                    678  \n",
      "17                                    721  \n",
      "18                                    515  \n",
      "19                                    505  \n",
      "20                                    613  \n",
      "21                                    346  \n",
      "22                                    792  \n",
      "23                                    804  \n",
      "24                                    351  \n",
      "25                                   2490  \n",
      "26                                    729  \n",
      "27                                   1754  \n",
      "28                                   1628  \n",
      "29                                    944  \n",
      "30                                   1275  \n",
      "31                                    444  \n",
      "32                                   1557  \n",
      "33                                   3404  \n",
      "34                                   2422  \n",
      "35                                   1220  \n",
      "36                                    938  \n",
      "37                                   3599  \n",
      "38                                    880  \n",
      "39                                   2360  \n",
      "40                                   1465  \n",
      "41                                   2838  \n",
      "42                                   1309  \n",
      "43                                    846  \n",
      "44                                   2308  \n",
      "45                                   2399  \n",
      "46                                   3393  \n",
      "47                                   1261  \n",
      "48                                     82  \n",
      "49                                    468  \n",
      "50                                   1240  \n",
      "51                                    361  \n",
      "52                                     17  \n",
      "53                                     14  \n",
      "54                                     34  \n",
      "55                                      2  \n"
     ]
    }
   ],
   "source": [
    "############### GOOD PRIMING Filter ##########\n",
    "#\n",
    "#    Here we assume the NNNNN is no longer on Read1 and I used 'trimmed_R1R2() function'\n",
    "#   LAM gene specific primer on READ 1 in this case. The program only understnad checing primer 1***\n",
    "\n",
    "# make a dataframe to capture all of the priming information and put it in the 'results' folder\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','all_priming.xlsx')\n",
    "    \n",
    "## inputs for correct_priming2() function\n",
    "mismatches =2                       # the number of mismatches you can have in the primer and downstream seq total\n",
    "downstream = 10                     # lenght of sequence downstream of the primer\n",
    "trimmed_R1R2 = True                 #if the file has been already tri\n",
    "removePrimerPlusDownstream = False  # remove the primer/downstream seq if it is good (good for guideseq)\n",
    "exportMismatch = True               # export the file of mismatches sequences\n",
    "\n",
    "for i in range(56):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "\n",
    "    #5primer is everything but AT, AT is for checking mispriming. The full sequence is the olgio from guideseq.\n",
    "    #EVERYTHING IS CAPITAL\n",
    "    #                       the extra TGTGCC has a mutation T>G in the hdr plasmid\n",
    "    #                    \n",
    "    ThreePrimeEnd_seq =       'TGTCACAGTGCAGCTCACTCAGTGTGGC'\n",
    "    #      Ch11:5226605:5226627                   \n",
    "    ThrePrimeEnd_primeronly = 'TGTCACAGTGCAGCTCACTCAG'\n",
    "    \n",
    "    #3primer \n",
    "    FivePrimeEnd_seq =            'CCATCTATTGCTTACATTTGCTTCTGACACAACTGTGTTCAC'\n",
    "    #      Ch11:5227054:5227084\n",
    "    FivePrimeEnd_seq_primeronly = 'CCATCTATTGCTTACATTTGCTTCTGACAC'\n",
    "\n",
    "    direction = amplicon_info['Direction']\n",
    "\n",
    "    if direction == 3:\n",
    "        primer_seq_plus_downstream = ThreePrimeEnd_seq\n",
    "        primer_seq = ThrePrimeEnd_primeronly\n",
    "    elif direction == 5:\n",
    "        primer_seq_plus_downstream = FivePrimeEnd_seq\n",
    "        primer_seq = FivePrimeEnd_seq_primeronly\n",
    "    \n",
    "    df_sample_results = correct_priming2(directory, amplicon_info, primer_seq, primer_seq_plus_downstream, \n",
    "                                          mismatches, trimmed_R1R2, removePrimerPlusDownstream,\n",
    "                                          exportMismatch)\n",
    "    #add the results to the ongoing dataframe        \n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "    print('done with sample', i)\n",
    "\n",
    "#export the final table\n",
    "results_df_all.to_excel(results_file)    \n",
    "print(results_df_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n",
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n",
      "done with sample 24\n",
      "done with sample 25\n",
      "done with sample 26\n",
      "done with sample 27\n",
      "done with sample 28\n",
      "done with sample 29\n",
      "done with sample 30\n",
      "done with sample 31\n",
      "done with sample 32\n",
      "done with sample 33\n",
      "done with sample 34\n",
      "done with sample 35\n",
      "done with sample 36\n",
      "done with sample 37\n",
      "done with sample 38\n",
      "done with sample 39\n",
      "done with sample 40\n",
      "done with sample 41\n",
      "done with sample 42\n",
      "done with sample 43\n",
      "done with sample 44\n",
      "done with sample 45\n",
      "done with sample 46\n",
      "done with sample 47\n",
      "done with sample 48\n",
      "done with sample 49\n",
      "done with sample 50\n",
      "done with sample 51\n",
      "done with sample 52\n",
      "done with sample 53\n",
      "done with sample 54\n",
      "done with sample 55\n"
     ]
    }
   ],
   "source": [
    "### TRIMMING ####\n",
    "#need to trim off the end of the short reads. This is for amplicons that were too short and have the other side on them.\n",
    "\n",
    "direction5primer = 'ATACCGTTATTAACATATGACAACTCAATTAAAC'\n",
    "direction3primer = 'TGTCACAGTGCAGCTCACTCAG' \n",
    "adapter ='GACTATAGGGCACGCGTGG'\n",
    "\n",
    "for i in range(56):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trim_short_fastq(directory, amplicon_info, direction5primer, direction3primer, adapter)\n",
    "    \n",
    "    print('done with sample', i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need to make an new bowtie2 index file that includes targeting for alignment agains the whole genome so it is all in one sheet together. \n",
    "\n",
    "### Other option would be to align it to the amplicon, extract unaligned files and then align to the genome but seems cleaner this way. \n",
    "#### Ideally every sequence is unique between the targeting vector and genome.\n",
    "\n",
    "\n",
    "1. Build your fastas of interest and label .fa files.\n",
    "    1. You need fasta of hg38 or reference genome. You can pull this from downloaded bowtie indexed sampels and then use the following command to turn the index into a fasta file: bowtie2-inspect hg38 > hg38.fa   \n",
    "    2. Put all the fasta files in the same folder. Should also use the transfected plasmid\n",
    "2. index the files with bowtie\n",
    "    1. use the command bowtie2-build -f pE049,pe038_mc.fa,hg38.fa -p hg38_plus_targetvectorandplasmid\n",
    "    2. this has the -p to make it take less ram in my case.\n",
    "    3. In this case it adds the hg38 and the minicircle targeting file together\n",
    "    4. I have a Intel® Core™ i7-5500U CPU @ 2.40GHz × 4 with 15.1 GiB ram and it required about 13.8 gigs of ram and 2 hours to do a hg38+small fasta index\n",
    "    5. be sure to pay attention to the name of the new indexed file. \"hg38_plus_targetvector\" in example above. Add it to the sample_info.csv sheet. Under the tab 'genome_plus_targeting'.\n",
    "    6. you can check it indexed correcctly: bowtie2-inspect -s hg38_plus_targetvector\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the reference alingment sequences\n",
    "\n",
    "- I will use the plasmid without the AAV sequence to follow backbone integration\n",
    "- I will use the AAV reference without the Homology arms, otherwise good stuff with align there\n",
    "- I will make amplicons with an HDR sequence. The hdr reference sequence will be directly copied out of\n",
    "     the .csv file and not altered.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N701    N5 :  N501\n",
      "sample name:  1.1.F.1    sample name:  Ctrl (#1) 5 end LAM-HTGTS\n",
      "rection type double_cut_same_chromosome_and_HDR\n"
     ]
    }
   ],
   "source": [
    "# Running the reference plasmid. This is acutally the AAV plasmid without the AAV HDR sequence\n",
    "# single smaple for testing\n",
    "\n",
    "\n",
    "amplicon_info = get_csv_data(directory, 0)\n",
    "print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "print('rection type', get_reaction_type(amplicon_info))\n",
    "\n",
    "create_plasmid_reference(directory, amplicon_info)\n",
    "create_AAV_reference(directory, amplicon_info)\n",
    "create_amplicon(directory, amplicon_info, file_genome_2bit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N701    N5 :  N501\n",
      "sample name:  1.1.F.1    sample name:  Ctrl (#1) 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N502\n",
      "sample name:  1.2.F.1    sample name:  Ctrl (#1) 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N504\n",
      "sample name:  1.3.F.1    sample name:  Ctrl (#1) 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N505\n",
      "sample name:  2.1.F.1    sample name:  Ctrl + AAV 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N506\n",
      "sample name:  2.2.F.1    sample name:  Ctrl + AAV 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N507\n",
      "sample name:  2.3.F.1    sample name:  Ctrl + AAV 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N508\n",
      "sample name:  3.1.F.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N701    N5 :  N510\n",
      "sample name:  3.2.F.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N501\n",
      "sample name:  3.3.F.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N502\n",
      "sample name:  4.1.F.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N504\n",
      "sample name:  4.2.F.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N505\n",
      "sample name:  4.3.F.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 5 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N506\n",
      "sample name:  1.1.R.1    sample name:  Ctrl (#1) 3 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N507\n",
      "sample name:  1.2.R.1    sample name:  Ctrl (#1) 3 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N508\n",
      "sample name:  1.3.R.1    sample name:  Ctrl (#1) 3 end LAM-HTGTS\n",
      "N7 : N702    N5 :  N510\n",
      "sample name:  2.1.R.1    sample name:  Ctrl + 25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N501\n",
      "sample name:  2.2.R.1    sample name:  Ctrl + 25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N502\n",
      "sample name:  2.3.R.1    sample name:  Ctrl + 25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N504\n",
      "sample name:  3.1.R.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N505\n",
      "sample name:  3.2.R.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N506\n",
      "sample name:  3.3.R.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N507\n",
      "sample name:  4.1.R.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N508\n",
      "sample name:  4.2.R.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N703    N5 :  N510\n",
      "sample name:  4.3.R.1    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+25pmol dsODN (#1) 3 end LAM-HTGTS\n",
      "N7 : N704    N5 :  N501\n",
      "sample name:  1.1.F.2    sample name:  Ctrl (#1) 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N502\n",
      "sample name:  1.2.F.2    sample name:  Ctrl (#1) 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N504\n",
      "sample name:  1.3.F.2    sample name:  Ctrl (#1) 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N505\n",
      "sample name:  2.1.F.2    sample name:  Ctrl + AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N506\n",
      "sample name:  2.2.F.2    sample name:  Ctrl + AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N507\n",
      "sample name:  2.3.F.2    sample name:  Ctrl + AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N508\n",
      "sample name:  3.1.F.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N704    N5 :  N510\n",
      "sample name:  3.2.F.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N705    N5 :  N501\n",
      "sample name:  3.3.F.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+AAV 5 end LAM-HTGTS (replicate 2)\n",
      "N7 : N705    N5 :  N502\n",
      "sample name:  4.1.F.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 5 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N504\n",
      "sample name:  4.2.F.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 5 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N505\n",
      "sample name:  4.3.F.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 5 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N506\n",
      "sample name:  1.1.R.2    sample name:  Ctrl (#1) 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N507\n",
      "sample name:  1.2.R.2    sample name:  Ctrl (#1) 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N508\n",
      "sample name:  1.3.R.2    sample name:  Ctrl (#1) 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N705    N5 :  N510\n",
      "sample name:  2.1.R.2    sample name:  Ctrl + AAV 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N706    N5 :  N501\n",
      "sample name:  2.2.R.2    sample name:  Ctrl + AAV 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N706    N5 :  N502\n",
      "sample name:  2.3.R.2    sample name:  Ctrl + AAV 3 end LAM-HTGTS (replicate2)\n",
      "N7 : N706    N5 :  N504\n",
      "sample name:  3.1.R.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N706    N5 :  N505\n",
      "sample name:  3.2.R.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N706    N5 :  N506\n",
      "sample name:  3.3.R.2    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N706    N5 :  N507\n",
      "sample name:  4.1.R.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N706    N5 :  N508\n",
      "sample name:  4.2.R.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N706    N5 :  N510\n",
      "sample name:  4.3.R.2    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+ AAV 3 end LAM-HTGTS (replicate 2)\n",
      "N7 : N707    N5 :  N501\n",
      "sample name:  4.2.F.3    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+AAV 5 end LAM-HTGTS (replicate 3)\n",
      "N7 : N707    N5 :  N502\n",
      "sample name:  4.2.F.4    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+AAV 5 end LAM-HTGTS (replicate 4)\n",
      "N7 : N707    N5 :  N504\n",
      "sample name:  4.2.R.3    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+AAV 3 end LAM-HTGTS (replicate 3)\n",
      "N7 : N707    N5 :  N505\n",
      "sample name:  4.2.R.4    sample name:  Cas9D10A+ sgHBB1-1+sgHBB2-6+AAV 3 end LAM-HTGTS (replicate 4)\n",
      "N7 : N707    N5 :  N506\n",
      "sample name:  NC.F.1    sample name:  No-gDNA control 5 end LAM-HTGTS\n",
      "N7 : N707    N5 :  N507\n",
      "sample name:  NC.R.1    sample name:  No-gDNA  5 end LAM-HTGTS\n",
      "N7 : N707    N5 :  N508\n",
      "sample name:  NC.F.2    sample name:  No-gDNA control 5 end LAM-HTGTS\n",
      "N7 : N707    N5 :  N510\n",
      "sample name:  NC.R.2    sample name:  No-gDNA control 5 end LAM-HTGTS\n"
     ]
    }
   ],
   "source": [
    "######## GENERATING REFERENCE SEQUENCES ###########\n",
    "#\n",
    "# MAKE SURE PLASMID DOESNT HAVE THE AAV PORTION IN IT\n",
    "# MAKE SURE AAV DOESN'T HAVE HDR ARMS IN IT\n",
    "\n",
    "\n",
    "for i in range(56):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "    print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "    get_reaction_type(amplicon_info)\n",
    "\n",
    "    create_plasmid_reference(directory, amplicon_info)\n",
    "    \n",
    "    create_AAV_reference(directory, amplicon_info)\n",
    "    create_amplicon(directory, amplicon_info, file_genome_2bit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N7 : N703    N5 :  N505\n",
      "sample name:  3.2.R.1    sample name:  Cas9WT+ sgHBB1-1+sgHBB2-6+AAV (#1) 3 end LAM-HTGTS\n",
      "rection type double_cut_same_chromosome_and_HDR\n"
     ]
    }
   ],
   "source": [
    "#try out the alignment to the plasmid backbone with the AAV/HDR virus removed\n",
    "\n",
    "\n",
    "amplicon_info = get_csv_data(directory, 19) #cas9 cutting sample\n",
    "print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "print('rection type', get_reaction_type(amplicon_info))\n",
    "\n",
    "\n",
    "#align_plasmid_local(directory, amplicon_info, ncpu=12)\n",
    "# use a mapQ score of >1\n",
    "#extract_unmapped_reads_plasmid(directory, amplicon_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_alignments_plasmid_and_AAV(dir_sample, amplicon_info, min_MAPQ, file_genome_2bit, do_plasmid):\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "        \n",
    "    exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "\n",
    "    file_UMI = create_filename(dir_sample, N7, N5, 'umifastqgz')\n",
    "    UMI_dict = create_barcode_dict(file_UMI)\n",
    "    \n",
    "    results_folder = os.path.join(exp_dir, 'results')\n",
    "    if not os.path.exists(results_folder):\n",
    "        os.mkdir(results_folder)\n",
    "\n",
    "    results_file = create_filename(dir_sample, N7, N5, 'results_plasmid')\n",
    "\n",
    "    if do_plasmid:\n",
    "        file_sorted_bam_plasmid_local = create_filename(dir_sample, N7, N5, 'sorted_bam_plasmid_local')\n",
    "\n",
    "        bam_in_alignment_file = pysam.AlignmentFile(file_sorted_bam_plasmid_local, 'rb')\n",
    "        bam_in = bam_in_alignment_file.fetch()\n",
    "\n",
    "        genome = twobitreader.TwoBitFile(file_genome_2bit)  # Load genome. Used for getting the sequences\n",
    "        \n",
    "        length_to_test = 15  # We check this number of bases after the primer\n",
    "        uditas_primer_length = amplicon_info['end'] - amplicon_info['start']\n",
    "        \n",
    "        if amplicon_info['strand'] == '+':  # This is the UDiTaS oligo strand\n",
    "            #I had to add int() command to make this work for some reason\n",
    "            seq_after_uditas_primer = genome[amplicon_info['chr']][int(amplicon_info['end']):int((amplicon_info['end'] + length_to_test))]\n",
    "            \n",
    "        elif amplicon_info['strand'] == '-':\n",
    "            seq_after_uditas_primer = reverse_complement(genome[amplicon_info['chr']][int((amplicon_info['start'] - length_to_test)):(int(amplicon_info['start']))])\n",
    "        n_max_mismatches = 2  # We allow this number of mismatches between the read and the sequence after the primer\n",
    "\n",
    "        names_list_plasmid_genome = []\n",
    "        UMI_list_plasmid_genome = []\n",
    "        names_list_plasmid_only = []\n",
    "        UMI_list_plasmid_only = []\n",
    "        \n",
    "        for read in bam_in:\n",
    "            if read.mapping_quality >= min_MAPQ and not read.is_unmapped and not read.is_secondary:\n",
    "                if read.is_read2:  # R2 is the UDiTaS primer\n",
    "                    if read.is_reverse:\n",
    "                        seq_test = reverse_complement(read.query_sequence)[int(uditas_primer_length):int((uditas_primer_length + length_to_test))]\n",
    "                    else:\n",
    "                        seq_test = read.query_sequence[int(uditas_primer_length): int(uditas_primer_length + length_to_test)]\n",
    "                    # Sometimes, after cutadapt we have a read shorter than uditas_primer_length + length_to_test\n",
    "                    # We skip those directly without calculating hamm_dist, which doesn't make sense\n",
    "                    if (len(seq_test) == len(seq_after_uditas_primer.upper()) and\n",
    "                        hamm_dist(seq_test, seq_after_uditas_primer.upper()) <= n_max_mismatches):\n",
    "                        # Reads for which the R2 has genomic sequence after the UDiTaS primer\n",
    "                        UMI_list_plasmid_genome.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_genome.append(read.query_name)\n",
    "                    else: # We put those short reads into the plasmid only bucket\n",
    "                        UMI_list_plasmid_only.append(UMI_dict[read.query_name][0])\n",
    "                        names_list_plasmid_only.append(read.query_name)\n",
    "\n",
    "        total_reads_plasmid_genome = len(set(names_list_plasmid_genome))\n",
    "        total_reads_collapsed_plasmid_genome = len(set(UMI_list_plasmid_genome))\n",
    "        total_reads_plasmid_only = len(set(names_list_plasmid_only))\n",
    "        total_reads_collapsed_plasmid_only = len(set(UMI_list_plasmid_only))\n",
    "\n",
    "        results_df = pd.DataFrame({'target_plus_plasmid_total_reads': [total_reads_plasmid_genome],\n",
    "                                   'target_plus_plasmid_total_reads_collapsed': [total_reads_collapsed_plasmid_genome],\n",
    "                                   'plasmid_only_total_reads': [total_reads_plasmid_only],\n",
    "                                   'plasmid_only_total_reads_collapsed': [total_reads_collapsed_plasmid_only]\n",
    "                                   },\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "    else:\n",
    "        results_df = pd.DataFrame(index=np.arange(1),\n",
    "                                  columns=['target_plus_plasmid_total_reads',\n",
    "                                           'target_plus_plasmid_total_reads_collapsed',\n",
    "                                           'plasmid_only_total_reads',\n",
    "                                           'plasmid_only_total_reads_collapsed'])\n",
    "\n",
    "    results_df.to_excel(results_file)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This looks for AAV insertion weather or not \n",
    "# fastq_source = 'trimmed_fastq' or 'plasmid_align_exracted_fastq'\n",
    "\n",
    "def align_AAV_local(dir_sample, amplicon_info, ncpu=4, fastq_source):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    # exp_dir = create_filename(dir_sample, N7, N5, 'mainfolder')\n",
    "    \n",
    "    if fastq_source == 'trimmed_fastq':\n",
    "        file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "        file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "\n",
    "        file_sam_AAValign_all_fastq_local = create_filename(dir_sample, N7, N5, 'sam_AAValign_all_fastq_local')\n",
    "        file_sam_report_AAValign_all_fastq_local = create_filename(dir_sample, N7, N5, 'sam_report_AAValign_all_fastq_local')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_sam_AAValign_all_fastq_local)):\n",
    "            os.mkdir(os.path.dirname(file_sam_AAValign_all_fastq_local))\n",
    "\n",
    "        file_bam_AAV_allfastq_local = create_filename(dir_sample, N7, N5, 'bam_AAValign_all_fastq_local')\n",
    "        file_sorted_bam_AAV_allfastq_local = create_filename(dir_sample, N7, N5, 'sorted_bam_AAValign_all_fastq_local')\n",
    "        # file_sorted_bai_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bai_genome_local')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_bam_AAV_allfastq_local)):\n",
    "            os.mkdir(os.path.dirname(file_bam_AAV_allfastq_local))\n",
    "    \n",
    "    if fastq_source == 'plasmid_align_exracted_fastq':\n",
    "        file_cutadapt_R1 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R1fastq')\n",
    "        file_cutadapt_R2 = create_filename(dir_sample, N7, N5, 'unmapped_plasmid_R2fastq')\n",
    "\n",
    "        file_sam_AAV_plasmidextractFastq_local = create_filename(dir_sample, N7, N5, 'samfile_bam_AAV_plasmidextractFastq_local')\n",
    "        file_sam_report_AAV_plasmidextractFastq_local = create_filename(dir_sample, N7, N5, 'sam_report_AAV_plasmidextractFastq_local')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_sam_AAV_plasmidextractFastq_local)):\n",
    "            os.mkdir(os.path.dirname(file_sam_AAV_plasmidextractFastq_local))\n",
    "\n",
    "        file_bam_AAV_plasmidextractFastq_local = create_filename(dir_sample, N7, N5, 'bam_AAV_plasmidextractFastq_local')\n",
    "        file_sorted_bam_AAV_plasmidextractFastq_local = create_filename(dir_sample, N7, N5, 'sorted_bam_AAV_plasmidextractFastq_local')\n",
    "        # file_sorted_bai_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bai_genome_local')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_bam_AAV_plasmidextractFastq_local)):\n",
    "            os.mkdir(os.path.dirname(file_bam_AAV_plasmidextractFastq_local))\n",
    "\n",
    "    # local alignment to the genome with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "\n",
    "    folder_amplicons = create_filename(dir_sample, N7, N5, 'amplicons')\n",
    "\n",
    "    os.chdir(folder_amplicons)\n",
    "\n",
    "    bowtie2_command = ['bowtie2', '--local', '-p', str(ncpu),\n",
    "                       '-X', '5000', '-k', '2', '-x', 'plasmid',\n",
    "                             '-1', file_cutadapt_R1, '-2', file_cutadapt_R2,\n",
    "                             '-S', file_sam_plasmid_local]\n",
    "\n",
    "    handle_sam_report_genome_local = open(file_sam_report_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_genome_local)\n",
    "\n",
    "    handle_sam_report_genome_local.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_plasmid_local_command = ['samtools', 'view', '-Sb', file_sam_plasmid_local]\n",
    "\n",
    "    handle_file_bam_plasmid_local = open(file_bam_plasmid_local, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_plasmid_local_command, stdout=handle_file_bam_plasmid_local)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_plasmid_local_command = ['samtools', 'sort', file_bam_plasmid_local, '-o', file_sorted_bam_plasmid_local]\n",
    "\n",
    "    subprocess.call(sort_bam_plasmid_local_command)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_plasmid_local_index_command = ['samtools', 'index', file_sorted_bam_plasmid_local]\n",
    "    subprocess.call(create_bam_plasmid_local_index_command)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(file_sam_plasmid_local)\n",
    "    os.remove(file_bam_plasmid_local)\n",
    "\n",
    "    os.chdir(initial_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## GENERATING REFERENCE SEQUENCES ###########\n",
    "#\n",
    "# MAKE SURE PLASMID DOESNT HAVE THE AAV PORTION IN IT\n",
    "# MAKE SURE AAV DOESN'T HAVE HDR ARMS IN IT\n",
    "\n",
    "\n",
    "for i in range(56):\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('N7 :', amplicon_info['index_I1'], \"   N5 : \", amplicon_info['index_I2'])\n",
    "    print (\"sample name: \", amplicon_info['name'], \"   sample name: \", amplicon_info['description'])\n",
    "    \n",
    "    align_plasmid_local(directory, amplicon_info, ncpu=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the unmapped reads\n",
    "extract_unmapped_reads_plasmid(directory, amplicon_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the plasmid analysis to coudn plasmid integration events\n",
    "result_plasmid_df = analyze_alignments_plasmid(directory, amplicon_info, min_MAPQ, file_genome_2bit, True)\n",
    "result_plasmid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align against our suite of amplicons\n",
    "align_amplicon(directory, amplicon_info, check_plasmid_insertions, ncpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will extract unmap reads new folder (files that did not align to the predicted structural variants)\n",
    "extract_unmapped_reads_amplicons(directory, amplicon_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
