{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "import shutil\n",
    "\n",
    "from AAVseq.AAVseq_helpersDanner import *\n",
    "from AAVseq.AAVseqDanner import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Danner_AAVseqLogic\n",
    "\n",
    "#  This is a simliar to the guideseq pipeline. Different than the oirignal guideseq pipeline but built in a simliar form. \n",
    "## It checks for the on target priming, the uses bowtie2 trimming off the adapter seq. Then exports a bed file for comparing to CRISPRgold\n",
    "\n",
    "\n",
    "#### 1. Check reads were correctly primed.\n",
    "#### 2 Trim reads \n",
    "#### 3. Align the reads against the whole geneome with local alignment. \n",
    "#### 4. Alignprocess bam file and pull out the high mapQ reads\n",
    "#### 5. convert to bed\n",
    "#### A3. Do global end-to-end alignment\n",
    "#### A4 global end-to-end\n",
    "#### A5 convert to bed\n",
    "\n",
    "It is important to trim R1 and R2 because if it is short then the read oges onto the chip. Also we will use global and local and compare the results because it is hard to trim to the end of the AAV due ot the random nature of hte integration.\n",
    "\n",
    "\n",
    "\n",
    "We use read1 for checking priming. Also we could use that for mapping (or paired end). On both the 3 and 5' direction the first 34 nucleotides of the read contain the integrated ODN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "\n",
    "directory = '/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC'\n",
    "\n",
    "#this is a minimal directory of only 300 files for quick debugging\n",
    "#directory = '/Workspace/Spaced_Nicking/GuideSeq_MiniSeq1/10000files'\n",
    "\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "When you put a universal primer on the ends of everything, every mispriming event will amplify. An effect we normally don't deal with. I did nested PCR to reduce this. However 85% of the alignments in the UDITAS data I looked at seemed to be mispriming. They did all their blasting and analysis before removing mispriming. But to save computational power and remove error early on I will discard mispriming events. \n",
    "They discard these only for plasmid alignments analyze_alignments_plasmid for some reason which comes from the bam file.\n",
    "\n",
    "### for guideseq read1 is where the ODN primer binds and so that is how you tell targeting. For the reverse it was binidng to the transposon which is random but then the seq primer binds right on it so the the read for read2 begins in the genomic sequence. the Rev primer could misprime but it shouldnt matter as it would then just bind and make smaller amplicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n",
      "    sample_name    i7    i5  total_reads  reads_with_good_priming  \\\n",
      "0   AAV_seq_1.1  N701  S502       770517                        5   \n",
      "1   AAV_seq_1.2  N701  S503       639421                        2   \n",
      "2   AAV_seq_1.3  N701  S505       524043                        3   \n",
      "3   AAV_seq_2.1  N702  S502       258548                   133559   \n",
      "4   AAV_seq_2.2  N702  S503       197160                   117796   \n",
      "5   AAV_seq_2.3  N702  S505       167655                   103758   \n",
      "6   AAV_seq_3.1  N703  S502       250131                   185015   \n",
      "7   AAV_seq_3.2  N703  S503       169333                   132932   \n",
      "8   AAV_seq_3.3  N703  S505       211348                   167826   \n",
      "9   AAV_seq_4.1  N704  S502       174030                   116810   \n",
      "10  AAV_seq_4.2  N704  S503       132988                   102676   \n",
      "11  AAV_seq_4.3  N704  S505        50745                    43222   \n",
      "12  AAV_seq_5.1  N705  S502      1189914                        9   \n",
      "13  AAV_seq_5.2  N705  S503       936689                        6   \n",
      "14  AAV_seq_5.3  N705  S505       506254                        5   \n",
      "\n",
      "    reads_with_guideseq_primer_misprimed  \\\n",
      "0                                   2332   \n",
      "1                                   2567   \n",
      "2                                   5323   \n",
      "3                                  20215   \n",
      "4                                  15648   \n",
      "5                                  16451   \n",
      "6                                  20261   \n",
      "7                                  14476   \n",
      "8                                  12527   \n",
      "9                                   8921   \n",
      "10                                  3117   \n",
      "11                                  1350   \n",
      "12                                  8454   \n",
      "13                                 10130   \n",
      "14                                 11834   \n",
      "\n",
      "    reads_with_indexing_primer_mispriming  \n",
      "0                                  768180  \n",
      "1                                  636852  \n",
      "2                                  518717  \n",
      "3                                  104774  \n",
      "4                                   63716  \n",
      "5                                   47446  \n",
      "6                                   44855  \n",
      "7                                   21925  \n",
      "8                                   30995  \n",
      "9                                   48299  \n",
      "10                                  27195  \n",
      "11                                   6173  \n",
      "12                                1181451  \n",
      "13                                 926553  \n",
      "14                                 494415  \n"
     ]
    }
   ],
   "source": [
    "#the amplicon info is related to the line on the csv file. It is indexed from 0.\n",
    "#it is on my extera space so need to make sure that is mounted. (first thing to check if it throws and error)\n",
    "\n",
    "\n",
    "# THIS IS WHAT RUNS THE PRIMER CHECK THROUGH ALL SAMPLES\n",
    "#input the sample range or list below\n",
    "\n",
    "\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','all_priming.xlsx')\n",
    "    \n",
    "\n",
    "#make results tree\n",
    "# 15 samples\n",
    "\n",
    "for i in range(15):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "\n",
    "    #5primer is everything but AT, AT is for checking mispriming. The full sequence is the olgio from guideseq.\n",
    "    #EVERYTHING IS CAPITAL\n",
    "    \n",
    "    # only use 3' as the ends are symetrial so put in 3 on the .csv sheet\n",
    "    guideseq3_seq = 'TCTCTGCGCGCTCGCTCGCTCACTGA'\n",
    "    guideseq3_primeronly = 'TCTCTGCGCGCTCGCTCG'\n",
    "    #3primer is everything but the final AC. The AC is for checking mispriming\n",
    "    guideseq5_seq = ''\n",
    "    guideseq5_primeronly = ''\n",
    "\n",
    "    direction = amplicon_info['Direction']\n",
    "    \n",
    "    #removed the section choosing between the 5' direction and 3' because it's symmetric\n",
    "    primer_seq_plus_downstream = guideseq3_seq\n",
    "    primer_seq = guideseq3_primeronly\n",
    "    \n",
    "    df_sample_results = correct_priming_guideseq(directory, amplicon_info, primer_seq, primer_seq_plus_downstream)\n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "    print('done with sample', i)\n",
    "\n",
    "print(results_df_all)\n",
    "results_df_all.to_excel(results_file)    \n",
    "#print reults to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n"
     ]
    }
   ],
   "source": [
    "### TRIMMING ####\n",
    "#need to trim off the end of the short reads. This is for amplicons that were too short and have the other side on them.\n",
    "# expect more trimmed read 2 and than read 1. Read 2 is longer htan read one as we trim off the ~30 bases of good priming \n",
    "# form read1 so sort amplicons get trimmed for read2 before being trimmed for read1.\n",
    "\n",
    "for i in range(15):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trim_AAVseq(directory, amplicon_info)\n",
    "    \n",
    "    print('done with sample', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes\n"
     ]
    }
   ],
   "source": [
    "# BOWTIE2_INDEXES are needed for global alignments\n",
    "#check in bash: > ECHO $GENOMES_2BIT\n",
    "%env BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need to make an new bowtie2 index file that includes targeting for alignment agains the whole genome so it is all in one sheet together. \n",
    "\n",
    "### Other option would be to align it to the amplicon, extract unaligned files and then align to the genome but seems cleaner this way. \n",
    "#### Ideally every sequence is unique between the targeting vector and genome.\n",
    "\n",
    "\n",
    "1. Build your fastas of interest and label .fa files.\n",
    "    1. You need fasta of hg38 or reference genome. You can pull this from downloaded bowtie indexed sampels and then use the following command to turn the index into a fasta file: bowtie2-inspect hg38 > hg38.fa   \n",
    "    2. Put all the fasta files in the same folder. Should also use the transfected plasmid\n",
    "2. index the files with bowtie\n",
    "    1. use the command bowtie2-build -f pE049,pe038_mc.fa,hg38.fa -p hg38_plus_targetvectorandplasmid\n",
    "    2. this has the -p to make it take less ram in my case.\n",
    "    3. In this case it adds the hg38 and the minicircle targeting file together\n",
    "    4. I have a Intel® Core™ i7-5500U CPU @ 2.40GHz × 4 with 15.1 GiB ram and it required about 13.8 gigs of ram and 2 hours to do a hg38+small fasta index\n",
    "    5. be sure to pay attention to the name of the new indexed file. \"hg38_plus_targetvector\" in example above. Add it to the sample_info.csv sheet. Under the tab 'genome_plus_targeting'.\n",
    "    6. you can check it indexed correcctly: bowtie2-inspect -s hg38_plus_targetvector\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we blast the correctly primed sequences.\n",
    "We don't need to trim off anything. But we should remove the length of the ODN primer sequence before blasting for Read1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_guideseq_genome_local(dir_sample, amplicon_info, assembly, single_or_paired = 'single', ncpu=12, keep_sam=0):\n",
    "\n",
    "    # We first check if the experiment had any guides\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    \n",
    "    #input\n",
    "    # Read1 for guideSeq they way Chu did it\n",
    "    file_R1 = create_filename(dir_sample, N7, N5, 'R1trimmed')\n",
    "    file_R2 = create_filename(dir_sample, N7, N5, 'R2trimmed')\n",
    "    \n",
    "    if single_or_paired == 'single':\n",
    "        file_sam_genome_local = create_filename(dir_sample, N7, N5, 'sam_genome_local_single')\n",
    "        file_sam_report_genome_local = create_filename(dir_sample, N7, N5, 'sam_report_genome_local_single')\n",
    "    \n",
    "        if not os.path.exists(os.path.dirname(file_sam_genome_local)):\n",
    "            os.mkdir(os.path.dirname(file_sam_genome_local))\n",
    "\n",
    "        file_bam_genome_local = create_filename(dir_sample, N7, N5, 'bam_genome_local_single')\n",
    "        file_sorted_bam_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_local_single')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_bam_genome_local)):\n",
    "            os.mkdir(os.path.dirname(file_bam_genome_local))\n",
    "    \n",
    "    elif single_or_paired == 'paired':\n",
    "        file_sam_genome_local = create_filename(dir_sample, N7, N5, 'sam_genome_local_paired')\n",
    "        file_sam_report_genome_local = create_filename(dir_sample, N7, N5, 'sam_report_genome_local_paired')\n",
    "    \n",
    "        if not os.path.exists(os.path.dirname(file_sam_genome_local)):\n",
    "            os.mkdir(os.path.dirname(file_sam_genome_local))\n",
    "    \n",
    "        file_bam_genome_local = create_filename(dir_sample, N7, N5, 'bam_genome_local_paired')\n",
    "        file_sorted_bam_genome_local = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_local_paired')\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(file_bam_genome_local)):\n",
    "            os.mkdir(os.path.dirname(file_bam_genome_local))\n",
    "    \n",
    "        \n",
    "    # local alignment to the genome with bowtie2\n",
    "    initial_dir = os.getcwd()\n",
    "    \n",
    "    #-X length for paired end fragment -k number of distict matches\n",
    "    if single_or_paired == 'single':\n",
    "        \n",
    "        bowtie2_command = ['bowtie2', '--local', '-p', str(ncpu),\n",
    "                           '-k', '4', '-x', assembly,\n",
    "                           '-U', file_R1, '-S', file_sam_genome_local]\n",
    "    elif single_or_paired == 'paired':\n",
    "        bowtie2_command = ['bowtie2', '--local', '-p', str(ncpu),\n",
    "                            '-X', '5000', '-k', '4', '-x', assembly,\n",
    "                            '-1', file_R1, '-2', file_R2,\n",
    "                            '-S', file_sam_genome_local]\n",
    "\n",
    "    handle_sam_report_genome_local = open(file_sam_report_genome_local, 'wb')\n",
    "\n",
    "    subprocess.call(bowtie2_command, stderr=handle_sam_report_genome_local)\n",
    "\n",
    "    handle_sam_report_genome_local.close()\n",
    "\n",
    "    # convert sam to bam\n",
    "    sam_to_bam_genome_local_command = ['samtools', 'view', '-Sb', file_sam_genome_local]\n",
    "\n",
    "    handle_file_bam_genome_local = open(file_bam_genome_local, 'wb')\n",
    "\n",
    "    subprocess.call(sam_to_bam_genome_local_command, stdout=handle_file_bam_genome_local)\n",
    "\n",
    "    # sort bam files\n",
    "    sort_bam_genome_local_command = ['samtools', 'sort', file_bam_genome_local, '-o', file_sorted_bam_genome_local]\n",
    "\n",
    "    subprocess.call(sort_bam_genome_local_command)\n",
    "\n",
    "    # Clean up\n",
    "    if keep_sam == 0:\n",
    "        os.remove(file_sam_genome_local)\n",
    "        print('sam file deleted')\n",
    "\n",
    "    \n",
    "    os.remove(file_bam_genome_local)\n",
    "\n",
    "    # Create bam index files\n",
    "    create_bam_genome_local_index_command = ['samtools', 'index', file_sorted_bam_genome_local]\n",
    "    subprocess.call(create_bam_genome_local_index_command)\n",
    "\n",
    "    os.chdir(initial_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def guideseq_filtered_mapq_AS_primary(dir_sample, global_or_local, amplicon_info, single_or_paired = 'single', min_MAPQ = 25, min_AS=-180):\n",
    "    #function beginning\n",
    "    # define samples\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    name = amplicon_info['name']\n",
    "\n",
    "\n",
    "    \n",
    "    if global_or_local == 'global':\n",
    "        if single_or_paired == 'single':\n",
    "            bam_file = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_global_single')\n",
    "            final_trimmed_bam_filtered_file = create_filename(dir_sample, N7, N5, 'filtered_and_sorted_genome_global_single')\n",
    "        elif single_or_paired == 'paired':\n",
    "            bam_file = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_global_paired')\n",
    "            final_trimmed_bam_filtered_file = create_filename(dir_sample, N7, N5, 'filtered_and_sorted_genome_global_paired')\n",
    " \n",
    "    if global_or_local == 'local':\n",
    "        if single_or_paired == 'single':\n",
    "            bam_file = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_local_single')\n",
    "            final_trimmed_bam_filtered_file = create_filename(dir_sample, N7, N5, 'filtered_and_sorted_genome_local_single')\n",
    "        elif single_or_paired == 'paired':\n",
    "            print('wooo')\n",
    "            bam_file = create_filename(dir_sample, N7, N5, 'sorted_bam_genome_local_paired')\n",
    "            final_trimmed_bam_filtered_file = create_filename(dir_sample, N7, N5, 'filtered_and_sorted_genome_local_paired')    \n",
    "    \n",
    "    all_reads_unfiltered = []\n",
    "    all_reads_pass_filter = []\n",
    "    print(bam_file)\n",
    "    bam_alignment_file = pysam.AlignmentFile(bam_file, 'rb')\n",
    "    bam_in = bam_alignment_file.fetch()\n",
    "    \n",
    "    #make output file\n",
    "    filtered_reads = pysam.AlignmentFile(final_trimmed_bam_filtered_file, \"wb\", template=bam_alignment_file)\n",
    "    \n",
    "    #test each read\n",
    "    for read in bam_in:\n",
    "        all_reads_unfiltered.append(read.query_name)\n",
    "        if read.has_tag('AS'):\n",
    "            read_AS = read.get_tag('AS')\n",
    "        #check read quality is good\n",
    "        if read.mapping_quality >= min_MAPQ and read_AS >= min_AS and not read.is_secondary:\n",
    "            all_reads_pass_filter.append(read.query_name)\n",
    "            filtered_reads.write(read)\n",
    "    filtered_reads.close()\n",
    "    bam_alignment_file.close()\n",
    "\n",
    "\n",
    "    count_unfiltered = len(all_reads_unfiltered)\n",
    "\n",
    "    count_filtered = len(all_reads_pass_filter)\n",
    "    \n",
    "    \n",
    "    \n",
    "    results_df = pd.DataFrame({'sample_name': [name],\n",
    "                               'i7': [N7],\n",
    "                               'i5': [N5],\n",
    "                               'single_or_paired_reads' : [single_or_paired],\n",
    "                               'all_alignments_count': [count_unfiltered],\n",
    "                               'filtered_alignments_count': [count_filtered]\n",
    "                               },\n",
    "                                  columns=['sample_name',\n",
    "                                           'i7',\n",
    "                                           'i5',\n",
    "                                           'single_or_paired_reads',\n",
    "                                           'all_alignments_count',\n",
    "                                           'filtered_alignments_count'])\n",
    "    print('single por paired', single_or_paired)\n",
    "    \n",
    "    print(results_df)   \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running row 0\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.1\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S502/bam_genome_local_files/N701_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.1  N701  S502                 paired                    17   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          6  \n",
      "-----  now making local bed file for AAV_seq_1.1   N701   S502\n",
      "made local bed file: N701 _ S502\n",
      "It is called AAV_seq_1.1\n",
      "doing the quantification of local alignments\n",
      "running row 1\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.2\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S503/bam_genome_local_files/N701_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.2  N701  S503                 paired                     6   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          0  \n",
      "-----  now making local bed file for AAV_seq_1.2   N701   S503\n",
      "made local bed file: N701 _ S503\n",
      "It is called AAV_seq_1.2\n",
      "doing the quantification of local alignments\n",
      "running row 2\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.3\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S505/bam_genome_local_files/N701_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.3  N701  S505                 paired                    16   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          0  \n",
      "-----  now making local bed file for AAV_seq_1.3   N701   S505\n",
      "made local bed file: N701 _ S505\n",
      "It is called AAV_seq_1.3\n",
      "doing the quantification of local alignments\n",
      "running row 3\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.1\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S502/bam_genome_local_files/N702_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.1  N702  S502                 paired                313590   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     120244  \n",
      "-----  now making local bed file for AAV_seq_2.1   N702   S502\n",
      "made local bed file: N702 _ S502\n",
      "It is called AAV_seq_2.1\n",
      "doing the quantification of local alignments\n",
      "running row 4\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.2\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S503/bam_genome_local_files/N702_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.2  N702  S503                 paired                191408   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     140511  \n",
      "-----  now making local bed file for AAV_seq_2.2   N702   S503\n",
      "made local bed file: N702 _ S503\n",
      "It is called AAV_seq_2.2\n",
      "doing the quantification of local alignments\n",
      "running row 5\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.3\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S505/bam_genome_local_files/N702_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.3  N702  S505                 paired                154030   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     135243  \n",
      "-----  now making local bed file for AAV_seq_2.3   N702   S505\n",
      "made local bed file: N702 _ S505\n",
      "It is called AAV_seq_2.3\n",
      "doing the quantification of local alignments\n",
      "running row 6\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.1\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S502/bam_genome_local_files/N703_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.1  N703  S502                 paired                313243   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     131294  \n",
      "-----  now making local bed file for AAV_seq_3.1   N703   S502\n",
      "made local bed file: N703 _ S502\n",
      "It is called AAV_seq_3.1\n",
      "doing the quantification of local alignments\n",
      "running row 7\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.2\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S503/bam_genome_local_files/N703_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.2  N703  S503                 paired                294410   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      75317  \n",
      "-----  now making local bed file for AAV_seq_3.2   N703   S503\n",
      "made local bed file: N703 _ S503\n",
      "It is called AAV_seq_3.2\n",
      "doing the quantification of local alignments\n",
      "running row 8\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.3\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S505/bam_genome_local_files/N703_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.3  N703  S505                 paired                298783   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      97937  \n",
      "-----  now making local bed file for AAV_seq_3.3   N703   S505\n",
      "made local bed file: N703 _ S505\n",
      "It is called AAV_seq_3.3\n",
      "doing the quantification of local alignments\n",
      "running row 9\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.1\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S502/bam_genome_local_files/N704_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.1  N704  S502                 paired                380881   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      67310  \n",
      "-----  now making local bed file for AAV_seq_4.1   N704   S502\n",
      "made local bed file: N704 _ S502\n",
      "It is called AAV_seq_4.1\n",
      "doing the quantification of local alignments\n",
      "running row 10\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.2\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S503/bam_genome_local_files/N704_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.2  N704  S503                 paired                331777   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      71570  \n",
      "-----  now making local bed file for AAV_seq_4.2   N704   S503\n",
      "made local bed file: N704 _ S503\n",
      "It is called AAV_seq_4.2\n",
      "doing the quantification of local alignments\n",
      "running row 11\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.3\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S505/bam_genome_local_files/N704_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.3  N704  S505                 paired                129429   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      39496  \n",
      "-----  now making local bed file for AAV_seq_4.3   N704   S505\n",
      "made local bed file: N704 _ S505\n",
      "It is called AAV_seq_4.3\n",
      "doing the quantification of local alignments\n",
      "running row 12\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.1\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S502/bam_genome_local_files/N705_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.1  N705  S502                 paired                    35   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          4  \n",
      "-----  now making local bed file for AAV_seq_5.1   N705   S502\n",
      "made local bed file: N705 _ S502\n",
      "It is called AAV_seq_5.1\n",
      "doing the quantification of local alignments\n",
      "running row 13\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.2\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S503/bam_genome_local_files/N705_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.2  N705  S503                 paired                    10   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          6  \n",
      "-----  now making local bed file for AAV_seq_5.2   N705   S503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made local bed file: N705 _ S503\n",
      "It is called AAV_seq_5.2\n",
      "doing the quantification of local alignments\n",
      "running row 14\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.3\n",
      "wooo\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S505/bam_genome_local_files/N705_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.3  N705  S505                 paired                     2   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          2  \n",
      "-----  now making local bed file for AAV_seq_5.3   N705   S505\n",
      "made local bed file: N705 _ S505\n",
      "It is called AAV_seq_5.3\n",
      "doing the quantification of local alignments\n"
     ]
    }
   ],
   "source": [
    "###  THIS IS FOR BLASTING THE LOCAL ALIGNMENT. WE WILL HAVE LIGATED AAV ON END OF READ AND SO WE SHOULD IGNORE THIS\n",
    "#\n",
    "#     This section does two things. It makes a bam file that is filtered for AS and MAPQ \n",
    "#     It quantifies these bam files and sorts them. Then it converts to a bed file.\n",
    "#\n",
    "\n",
    "                #### Required Arguments\n",
    "cpu = 12\n",
    "min_MAPQ = 50\n",
    "min_AS = -180\n",
    "\n",
    "\n",
    "                        #this does the acutal alignment for end-to-end\n",
    "do_align = 'on'\n",
    "single_or_paired_reads = \"paired\"     #can be 'single' or 'paired' for the read alignment\n",
    "\n",
    "\n",
    "                    #### WHAT SAMPLES TO RUN ####\n",
    "#lines_to_run = [15]\n",
    "lines_to_run = range(15)\n",
    "\n",
    "                    #for exporting summary of data\n",
    "results_df_all = pd.DataFrame()\n",
    "results_file = os.path.join(directory, 'results','local_alignment_filtered_summary.xlsx')\n",
    "\n",
    "\n",
    "for i in lines_to_run:\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('running row', i)\n",
    "    print('the analysis is on AAV-seq sample:', amplicon_info['name'])\n",
    "    reference_assembly = amplicon_info['genome']\n",
    "    sample_name = amplicon_info['name']\n",
    "    \n",
    "    if do_align == 'on':\n",
    "        #####this aligns everything after the break to end-to-end keep_sam=1 means keep the sam file\n",
    "        align_guideseq_genome_local(directory, amplicon_info, reference_assembly, single_or_paired_reads, cpu, keep_sam=1)\n",
    "\n",
    "\n",
    "    #### Process the alignment files to make a bam file of only high quality reads\n",
    "\n",
    "    #this filters for good alignments based on AS score and MapQ and exports a final indexed bam file.\n",
    "\n",
    "    df_sample_results = guideseq_filtered_mapq_AS_primary(directory, 'local', amplicon_info, single_or_paired_reads)\n",
    "    #this is a running dataframe of the clenaed up read summary\n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "\n",
    "\n",
    "    ### global alignment bed generation \n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    print('-----  now making local bed file for', sample_name, ' ',N7, ' ', N5 )\n",
    "\n",
    "\n",
    "    ##### Need to fix this!!!!!!!!!!!! the names of the input are not right and mabye i need to sort things\n",
    "    if single_or_paired_reads == \"single\":\n",
    "        genome_local_bed_file = create_filename(directory, N7, N5, 'guideseq_local_bed_single')\n",
    "        filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_local_single')\n",
    "    elif single_or_paired_reads == \"paired\":\n",
    "        genome_local_bed_file = create_filename(directory, N7, N5, 'guideseq_local_bed_paired')\n",
    "        filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_local_paired')\n",
    "\n",
    "    !bam2bed < {filtered_and_sorted_bam_file} > {genome_local_bed_file}\n",
    "    bed_folder = os.path.join(directory, 'bed_files')\n",
    "\n",
    "    if not os.path.exists(bed_folder):\n",
    "        os.mkdir(bed_folder)\n",
    "\n",
    "    file_location = create_filename(directory, N7, N5, 'bam_local')\n",
    "\n",
    "    new_bed_name = os.path.join(file_location, sample_name + '_' + 'local_'+ single_or_paired_reads + '.bed')\n",
    "\n",
    "    os.rename(genome_local_bed_file, new_bed_name)\n",
    "\n",
    "    shutil.copy(new_bed_name, bed_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('made local bed file:', N7, '_', N5 )\n",
    "    print('It is called', sample_name )\n",
    "    print('doing the quantification of local alignments')\n",
    "\n",
    " \n",
    "    \n",
    " \n",
    " ## export all the read summaries\n",
    "results_df_all.to_excel(results_file)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running row 0\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.1\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S502/bam_genome_global_files/N701_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.1  N701  S502                 paired                    10   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          6  \n",
      "-----  now making bed file for AAV_seq_1.1   N701   S502\n",
      "made global bed file: N701 _ S502\n",
      "It is called AAV_seq_1.1\n",
      "doing the quantification of global alignments\n",
      "running row 1\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.2\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S503/bam_genome_global_files/N701_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.2  N701  S503                 paired                     0   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          0  \n",
      "-----  now making bed file for AAV_seq_1.2   N701   S503\n",
      "made global bed file: N701 _ S503\n",
      "It is called AAV_seq_1.2\n",
      "doing the quantification of global alignments\n",
      "running row 2\n",
      "the analysis is on AAV-seq sample: AAV_seq_1.3\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N701_S505/bam_genome_global_files/N701_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_1.3  N701  S505                 paired                     5   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          2  \n",
      "-----  now making bed file for AAV_seq_1.3   N701   S505\n",
      "made global bed file: N701 _ S505\n",
      "It is called AAV_seq_1.3\n",
      "doing the quantification of global alignments\n",
      "running row 3\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.1\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S502/bam_genome_global_files/N702_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.1  N702  S502                 paired                202901   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     126879  \n",
      "-----  now making bed file for AAV_seq_2.1   N702   S502\n",
      "made global bed file: N702 _ S502\n",
      "It is called AAV_seq_2.1\n",
      "doing the quantification of global alignments\n",
      "running row 4\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.2\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S503/bam_genome_global_files/N702_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.2  N702  S503                 paired                131745   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     117517  \n",
      "-----  now making bed file for AAV_seq_2.2   N702   S503\n",
      "made global bed file: N702 _ S503\n",
      "It is called AAV_seq_2.2\n",
      "doing the quantification of global alignments\n",
      "running row 5\n",
      "the analysis is on AAV-seq sample: AAV_seq_2.3\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N702_S505/bam_genome_global_files/N702_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_2.3  N702  S505                 paired                128542   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     111047  \n",
      "-----  now making bed file for AAV_seq_2.3   N702   S505\n",
      "made global bed file: N702 _ S505\n",
      "It is called AAV_seq_2.3\n",
      "doing the quantification of global alignments\n",
      "running row 6\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.1\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S502/bam_genome_global_files/N703_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.1  N703  S502                 paired                190645   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     152162  \n",
      "-----  now making bed file for AAV_seq_3.1   N703   S502\n",
      "made global bed file: N703 _ S502\n",
      "It is called AAV_seq_3.1\n",
      "doing the quantification of global alignments\n",
      "running row 7\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.2\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S503/bam_genome_global_files/N703_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.2  N703  S503                 paired                171744   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     124750  \n",
      "-----  now making bed file for AAV_seq_3.2   N703   S503\n",
      "made global bed file: N703 _ S503\n",
      "It is called AAV_seq_3.2\n",
      "doing the quantification of global alignments\n",
      "running row 8\n",
      "the analysis is on AAV-seq sample: AAV_seq_3.3\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N703_S505/bam_genome_global_files/N703_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_3.3  N703  S505                 paired                160977   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     132600  \n",
      "-----  now making bed file for AAV_seq_3.3   N703   S505\n",
      "made global bed file: N703 _ S505\n",
      "It is called AAV_seq_3.3\n",
      "doing the quantification of global alignments\n",
      "running row 9\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.1\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S502/bam_genome_global_files/N704_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.1  N704  S502                 paired                206425   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     102855  \n",
      "-----  now making bed file for AAV_seq_4.1   N704   S502\n",
      "made global bed file: N704 _ S502\n",
      "It is called AAV_seq_4.1\n",
      "doing the quantification of global alignments\n",
      "running row 10\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.2\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S503/bam_genome_global_files/N704_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.2  N704  S503                 paired                179545   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     108036  \n",
      "-----  now making bed file for AAV_seq_4.2   N704   S503\n",
      "made global bed file: N704 _ S503\n",
      "It is called AAV_seq_4.2\n",
      "doing the quantification of global alignments\n",
      "running row 11\n",
      "the analysis is on AAV-seq sample: AAV_seq_4.3\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N704_S505/bam_genome_global_files/N704_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_4.3  N704  S505                 paired                 78550   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      48363  \n",
      "-----  now making bed file for AAV_seq_4.3   N704   S505\n",
      "made global bed file: N704 _ S505\n",
      "It is called AAV_seq_4.3\n",
      "doing the quantification of global alignments\n",
      "running row 12\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.1\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S502/bam_genome_global_files/N705_S502_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.1  N705  S502                 paired                    22   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          8  \n",
      "-----  now making bed file for AAV_seq_5.1   N705   S502\n",
      "made global bed file: N705 _ S502\n",
      "It is called AAV_seq_5.1\n",
      "doing the quantification of global alignments\n",
      "running row 13\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.2\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S503/bam_genome_global_files/N705_S503_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.2  N705  S503                 paired                     8   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          7  \n",
      "-----  now making bed file for AAV_seq_5.2   N705   S503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made global bed file: N705 _ S503\n",
      "It is called AAV_seq_5.2\n",
      "doing the quantification of global alignments\n",
      "running row 14\n",
      "the analysis is on AAV-seq sample: AAV_seq_5.3\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/N705_S505/bam_genome_global_files/N705_S505_paired.sorted.bam\n",
      "single por paired paired\n",
      "   sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0  AAV_seq_5.3  N705  S505                 paired                     2   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                          2  \n",
      "-----  now making bed file for AAV_seq_5.3   N705   S505\n",
      "made global bed file: N705 _ S505\n",
      "It is called AAV_seq_5.3\n",
      "doing the quantification of global alignments\n",
      "/home/eric/Data/Spaced_Nicking/AAVseq1_200930_MN00157_0064_A000H37GLC/results/global_alignment_filtered_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "###  ALIGN END-TO-END GLOBAL\n",
    "#s. It makes a bam file that is filtered for AS and MAPQ \n",
    "#   It quantifies these bam files and sorts them. Then it converts to a bed file.\n",
    "#\n",
    "\n",
    "                #### Required Arguments\n",
    "cpu = 12\n",
    "min_MAPQ = 50\n",
    "min_AS = -180\n",
    "\n",
    "             ### WHAT TYPE OF ANALYSIS ARE WE RUNNING #####\n",
    "\n",
    "\n",
    "            #### this does the acutal alignment for end-to-end\n",
    "do_align = 'off'\n",
    "single_or_paired_reads = \"paired\"   #can be 'single' or 'paired' for the read alignment\n",
    "\n",
    "            #### WHAT SAMPLES TO RUN ####\n",
    "#lines_to_run = [15]\n",
    "lines_to_run = range(15)\n",
    "\n",
    "    #for exporting summary of data\n",
    "results_df_all = pd.DataFrame()\n",
    "results_file = os.path.join(directory, 'results','global_alignment_filtered_summary.xlsx')\n",
    "\n",
    "\n",
    "for i in lines_to_run:\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('running row', i)\n",
    "    print('the analysis is on AAV-seq sample:', amplicon_info['name'])\n",
    "    reference_assembly = amplicon_info['genome']\n",
    "    sample_name = amplicon_info['name']\n",
    "    \n",
    "    if do_align == 'on':\n",
    "        #####this aligns everything after the break to end-to-end keep_sam=1 means keep the sam file\n",
    "        align_guideseq_end_to_end_genome_global(directory, amplicon_info, reference_assembly, single_or_paired_reads, cpu, keep_sam=1)\n",
    "\n",
    "\n",
    "    #### Process the alignment files to make a bam file of only high quality reads\n",
    "\n",
    "    #this filters for good alignments based on AS score and MapQ and exports a final indexed bam file.\n",
    "\n",
    "    df_sample_results = guideseq_filtered_mapq_AS_primary(directory, 'global', amplicon_info, single_or_paired_reads)\n",
    "    #this is a running dataframe of the clenaed up read summary\n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "\n",
    "\n",
    "    ### global alignment bed generation \n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    print('-----  now making bed file for', sample_name, ' ',N7, ' ', N5 )\n",
    "\n",
    "\n",
    "    ##### Need to fix this!!!!!!!!!!!! the names of the input are not right and mabye i need to sort things\n",
    "    if single_or_paired_reads == \"single\":\n",
    "        genome_global_bed_file = create_filename(directory, N7, N5, 'guideseq_global_bed_single')\n",
    "        filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_global_single')\n",
    "    elif single_or_paired_reads == \"paired\":\n",
    "        genome_global_bed_file = create_filename(directory, N7, N5, 'guideseq_global_bed_paired')\n",
    "        filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_global_paired')\n",
    "\n",
    "    !bam2bed < {filtered_and_sorted_bam_file} > {genome_global_bed_file}\n",
    "    bed_folder = os.path.join(directory, 'bed_files')\n",
    "\n",
    "    if not os.path.exists(bed_folder):\n",
    "        os.mkdir(bed_folder)\n",
    "\n",
    "    file_location = create_filename(directory, N7, N5, 'bam_global')\n",
    "\n",
    "    new_bed_name = os.path.join(file_location, sample_name + '_' + 'global_'+ single_or_paired_reads + '.bed')\n",
    "\n",
    "    os.rename(genome_global_bed_file, new_bed_name)\n",
    "\n",
    "    shutil.copy(new_bed_name, bed_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('made global bed file:', N7, '_', N5 )\n",
    "    print('It is called',sample_name )\n",
    "    print('doing the quantification of global alignments')\n",
    "\n",
    "\n",
    " ## export all the read summaries    \n",
    "#results_df_all.to_excel(results_file)    \n",
    "print(results_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listnumber2                 object\n",
      "Sequence                    object\n",
      "Name                        object\n",
      "Top off-target sites        object\n",
      "Strand                      object\n",
      "MutDist                      int64\n",
      "Risk                        object\n",
      "Annotation (if relevant)    object\n",
      "chr                         object\n",
      "position_start               int64\n",
      "position_end                object\n",
      "begin_site_range             int64\n",
      "end_site_range               int64\n",
      "dtype: object\n",
      "running row 1\n",
      "the analysis is on Guideseq sample: 2-1-3'GSP-TD\n",
      "index\n",
      "index N702 S502\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/results/N702_S502_2-1-3'GSP-TD_guide_count.xlsx\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/N702_S502/bam_genome_global_files\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/N702_S502/bam_genome_global_files/2-1-3'GSP-TD_paired.bed\n",
      "chr                     object\n",
      "chromStart               int64\n",
      "chromEnd                 int64\n",
      "name                    object\n",
      "MapQ                     int64\n",
      "strand                  object\n",
      "flag                     int64\n",
      "CIGAR                   object\n",
      "paired_name             object\n",
      "read1start               int64\n",
      "paired_amplicon_size     int64\n",
      "sequence                object\n",
      "quality_score           object\n",
      "a                       object\n",
      "b                       object\n",
      "c                       object\n",
      "d                       object\n",
      "e                       object\n",
      "f                       object\n",
      "g                       object\n",
      "h                       object\n",
      "i                       object\n",
      "dtype: object\n",
      "list of read hits: [1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "############ Use CIRPSR Gold and look at overlaps\n",
    "\n",
    "single_or_paired_reads = \"paired\"  #can be 'single' or 'paired' for the read alignment\n",
    "windowsize = 500\n",
    "\n",
    "#### WHAT SAMPLES TO RUN ####\n",
    "lines_to_run = [1]\n",
    "#lines_to_run = range(30)\n",
    "\n",
    "\n",
    "#off_target_sites \n",
    "crispr_gold_file = '/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/CrispRgold_predictions.xlsx'\n",
    "df_targets = pd.read_excel(crispr_gold_file, index_col=0)\n",
    "\n",
    "# new data frame with split guide location. CRISPRGOLD puts it all in at once\n",
    "new = df_targets[\"Position\"].str.split(\":\", expand = True) \n",
    "df_targets[\"chr\"]= new[0] \n",
    "df_targets[\"position_start\"]= new[1] \n",
    "df_targets[\"position_end\"]= new[2] \n",
    "df_targets.drop(columns =[\"Position\"], inplace = True) \n",
    "df_targets['position_start'] = df_targets['position_start'].astype(int)\n",
    "df_targets['begin_site_range'] = df_targets['position_start'] - windowsize\n",
    "df_targets['end_site_range'] = df_targets['position_start'] + windowsize\n",
    "\n",
    "print(df_targets.dtypes)\n",
    "\n",
    "#print(df_targets)\n",
    "\n",
    "\n",
    "for i in lines_to_run:\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    name = amplicon_info['name']\n",
    "    print('running row', i)\n",
    "    print('the analysis is on Guideseq sample:', name)\n",
    "    print('index',)\n",
    "    \n",
    "    #import bed file\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    print('index', N7, N5)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(results_file)\n",
    "\n",
    "    file_location = create_filename(directory, N7, N5, 'bam_global')   \n",
    "    print(file_location)\n",
    "    sample_name = amplicon_info['name']\n",
    "    bedfile = os.path.join(file_location, sample_name + '_' + single_or_paired_reads + '.bed')\n",
    "    print(bedfile)\n",
    "    \n",
    "    #needs to add header names to specify the number of columns so that \n",
    "    \n",
    "    header_names = ['chr', 'chromStart', 'chromEnd', 'name', 'MapQ', 'strand', 'flag', 'CIGAR', 'paired_name', 'read1start', 'paired_amplicon_size', 'sequence', 'quality_score','a','b','c','d','e','f','g','h','i']\n",
    "\n",
    "#    df_bed = pd.read_csv(bedfile, sep='\\t', comment='t', header=None)\n",
    "    df_bed = pd.read_csv(bedfile, sep='\\t', header=None, names = header_names)\n",
    "\n",
    "    \n",
    "    \n",
    "    #header = ['chr', 'chromStart', 'chromEnd', 'name', 'MapQ', 'strand', 'flag', 'CIGAR', 'paired_name', 'read1start', 'paired_amplicon_size', 'sequence', 'quality_score','a','b','c','d','e','f','g','h','i']\n",
    "    #df_bed.columns = header[:len(df_bed.columns)]\n",
    "    \n",
    "    print(df_bed.dtypes) \n",
    "    \n",
    "    read_hits = []\n",
    "    count = 0\n",
    "    for i,g in itertools.izip(df_bed.chromStart, df_bed.chr):\n",
    "        bed_alignment = i\n",
    "        chromosome = g\n",
    "        for a,b,c,d in itertools.izip(df_targets.listnumber2, df_targets.begin_site_range, df_targets.end_site_range, df_targets.chr): \n",
    "            counter_A = 0\n",
    "            if bed_alignment in range(b, c) and chromosome == d:\n",
    "                if counter = 0:\n",
    "                    print(b,c,'chromosome', d, ' guide:', a)\n",
    "                    read_hits.append(a)\n",
    "                    counter_A += 1\n",
    "                    print(b,c,'chromosome', d, ' guide:', a, 'for read starting at :', i)\n",
    "        count += 1 \n",
    "        if count >30:\n",
    "            break\n",
    "    results_df = pd.DataFrame({'sample_name': [name],\n",
    "                               'i7': [N7],\n",
    "                               'i5': [N5],\n",
    "                               'list_of_read_guide_matches' : [read_hits],\n",
    "                               },\n",
    "                                  columns=['sample_name',\n",
    "                                           'i7',\n",
    "                                           'i5',\n",
    "                                           'list_of_read_guide_matches'])            \n",
    "    \n",
    "    \n",
    "    \n",
    "    results_file = os.path.join(directory, 'results',N7 + '_' + N5 + '_'+ name +'_guide_count.xlsx')\n",
    "    \n",
    "    results_df.to_excel(results_file)    \n",
    "\n",
    "    print('list of read hits:',read_hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_filename(dir_sample, N7, N5, filetype):\n",
    "    main_folder = os.path.join(dir_sample, N7 + '_' + N5)\n",
    "    if filetype == 'mainfolder':\n",
    "        return main_folder\n",
    "    elif filetype == 'amplicons':\n",
    "        return os.path.join(main_folder, 'amplicons')\n",
    "    elif filetype == 'bam_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files')\n",
    "    elif filetype == 'bam_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files')\n",
    "    \n",
    "    elif filetype == 'R1fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq')\n",
    "    elif filetype == 'R1fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.fastq.gz')\n",
    "    elif filetype == 'R2fastq':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq')\n",
    "    elif filetype == 'R2fastqgz':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.fastq.gz')\n",
    "      \n",
    "    #### I added these as the sequences that were correctly primed\n",
    "    elif filetype == 'R1fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq')\n",
    "    elif filetype == 'R1fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R1.CorrPrime.fastq.gz')\n",
    "    elif filetype == 'R2fastq_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq')\n",
    "    elif filetype == 'R2fastqgz_CorrPrime':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + '_R2.CorrPrime.fastq.gz')\n",
    "    elif filetype == 'localpriming_data':\n",
    "        return os.path.join(main_folder, 'fastq_files', N7 + '_' + N5 + 'priming.xlsx')\n",
    "    elif filetype == 'priming_summary':\n",
    "        return os.path.join(main_folder, 'results', 'priming_summary.xlsx')\n",
    "    #####\n",
    "   \n",
    "    \n",
    "    elif filetype == 'R1trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R1.trimmed.fastq.gz')\n",
    "    elif filetype == 'R2trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R2.trimmed.fastq.gz')\n",
    "    elif filetype == 'trimmed_report':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '.trimmed.report.txt')\n",
    "    elif filetype == 'sam_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'sam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_qsorted_unmapped.bam')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'sam_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_amplicons_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_qsorted_amplicons_unmapped.bam')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_report':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '.unmapped.report.txt')\n",
    "    elif filetype == 'sam_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'results_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5)  # We will append the window size later\n",
    "    elif filetype == 'results_plasmid':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_plasmid.xlsx')\n",
    "    elif filetype == 'results_all_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_all_amplicons.xlsx')\n",
    "    elif filetype == 'results_genomewide':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_genomewide.xlsx')\n",
    "    elif filetype == 'summary_all_alignments':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_summary_all_alignments.xlsx')\n",
    "    elif filetype == 'read_counts':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_read_counts.xlsx')\n",
    "    ## more added\n",
    "    elif filetype == 'results_pipeline2_global':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_pipeline2_global.xlsx')\n",
    "    elif filetype == 'results_pipeline2_local':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_pipeline2_local.xlsx')\n",
    "    elif filetype == 'R1trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R1.trimmed.fastq.gz')\n",
    "    elif filetype == 'R2trimmed':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '_R2.trimmed.fastq.gz')\n",
    "    elif filetype == 'trimmed_report':\n",
    "        return os.path.join(main_folder, 'cutadapt_files', N7 + '_' + N5 + '.trimmed.report.txt')\n",
    "    elif filetype == 'sam_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_local':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_local':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'sam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_plasmid_local':\n",
    "        return os.path.join(main_folder, 'sam_plasmid_local_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_plasmid_local':\n",
    "        return os.path.join(main_folder, 'bam_plasmid_local_files', N7 + '_' + N5 + '_qsorted_unmapped.bam')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastq':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_plasmid_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_plasmid_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'plasmid_unmapped_fastq_files', N7 + '_' + N5 + '_plasmid_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'sam_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_amplicons':\n",
    "        return os.path.join(main_folder, 'sam_amplicon_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_amplicons_unmapped.bam')\n",
    "    elif filetype == 'qsorted_unmapped_bam_amplicons':\n",
    "        return os.path.join(main_folder, 'bam_amplicon_files', N7 + '_' + N5 + '_qsorted_amplicons_unmapped.bam')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastq':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq')\n",
    "    elif filetype == 'unmapped_amplicons_R1fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R1.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_R2fastqgz':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files',\n",
    "                            N7 + '_' + N5 + '_amplicons_unmapped_R2.fastq.gz')\n",
    "    elif filetype == 'unmapped_amplicons_report':\n",
    "        return os.path.join(main_folder, 'amplicons_unmapped_fastq_files', N7 + '_' + N5 + '.unmapped.report.txt')\n",
    "    elif filetype == 'sam_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam')\n",
    "    elif filetype == 'sam_report_genome_global':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam')\n",
    "    elif filetype == 'sorted_bai_genome_global':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '.sorted.bam.bai')\n",
    "    elif filetype == 'results_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5)  # We will append the window size later\n",
    "    elif filetype == 'results_plasmid':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_plasmid.xlsx')\n",
    "    elif filetype == 'results_all_amplicons':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_all_amplicons.xlsx')\n",
    "    elif filetype == 'results_genomewide':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_genomewide.xlsx')\n",
    "    elif filetype == 'summary_all_alignments':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_summary_all_alignments.xlsx')\n",
    "    elif filetype == 'read_counts':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_read_counts.xlsx')\n",
    "    ## more added\n",
    "    elif filetype == 'results_pipeline2_global':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_pipeline2_global.xlsx')\n",
    "    elif filetype == 'results_pipeline2_local':\n",
    "        return os.path.join(main_folder, 'results', N7 + '_' + N5 + '_results_pipeline2_local.xlsx')\n",
    "    elif filetype == 'sam_genome_global_single':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '_single.sam')\n",
    "    elif filetype == 'sam_genome_local_single':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '_single.sam')\n",
    "    elif filetype == 'sam_report_genome_global_single':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '_single.sam.report.txt')\n",
    "    elif filetype == 'sam_report_genome_local_single':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '_single.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single.bam')\n",
    "    elif filetype == 'bam_genome_local_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_single.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single.sorted.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_single.sorted.bam')\n",
    "    elif filetype == 'sam_genome_global_paired':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '_paired.sam')\n",
    "    elif filetype == 'sam_genome_local_paired':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '_paired.sam')\n",
    "    elif filetype == 'sam_report_genome_global_paired':\n",
    "        return os.path.join(main_folder, 'sam_genome_global_files', N7 + '_' + N5 + '_paired.sam.report.txt')\n",
    "    elif filetype == 'sam_report_genome_local_paired':\n",
    "        return os.path.join(main_folder, 'sam_genome_local_files', N7 + '_' + N5 + '_paired.sam.report.txt')\n",
    "    elif filetype == 'bam_genome_global_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired.bam')\n",
    "    elif filetype == 'bam_genome_local_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_paired.bam')\n",
    "    elif filetype == 'sorted_bam_genome_global_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired.sorted.bam')\n",
    "    elif filetype == 'sorted_bam_genome_local_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_paired.sorted.bam')\n",
    "    elif filetype == 'filtered_and_sorted_genome_global_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single_primary_as_mapq.sorted.bam')    \n",
    "    elif filetype == 'filtered_and_sorted_genome_local_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_single_primary_as_mapq.sorted.bam')    \n",
    "    elif filetype == 'genome_global_bed_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single_global.sorted.bed')\n",
    "    elif filetype == 'filtered_and_sorted_genome_global_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired_primary_as_mapq.sorted.bam')  \n",
    "    elif filetype == 'filtered_and_sorted_genome_local_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_local_files', N7 + '_' + N5 + '_paired_primary_as_mapq.sorted.bam')  \n",
    "    elif filetype == 'genome_global_bed_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired_global.sorted.bed')\n",
    "    elif filetype == 'guideseq_global_bed_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single.global.sorted.bed')\n",
    "    elif filetype == 'guideseq_global_bed_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired.global.sorted.bed')\n",
    "    elif filetype == 'guideseq_local_bed_single':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_single.local.sorted.bed')\n",
    "    elif filetype == 'guideseq_local_bed_paired':\n",
    "        return os.path.join(main_folder, 'bam_genome_global_files', N7 + '_' + N5 + '_paired.local.sorted.bed')\n",
    "###########################\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "apple += 1\n",
    "print(apple)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "apple += 1\n",
    "print(apple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(range(1,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
