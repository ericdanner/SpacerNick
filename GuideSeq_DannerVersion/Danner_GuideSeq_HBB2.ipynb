{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import itertools\n",
    "import operator\n",
    "import subprocess\n",
    "import twobitreader\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import pysam\n",
    "import shutil\n",
    "\n",
    "from guideseq_functions.guideseq_helpers import *\n",
    "from guideseq_functions.guideseq import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem log\n",
    "\n",
    "** makes sure you keep your I5 primers binding to the ODN sequence as this becomes \"Read1 by the machine\"\n",
    "1. do 200 long read for Read1 \n",
    "\n",
    "2.naming files and folder\n",
    "2. longer site in front of primer binding\n",
    "3. cut out amplicons that are 400-700 so I don't loose reads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Danner_GuideseqLogic\n",
    "\n",
    "#  This is a guideseq pipeline. Different than the oirignal but built in a simliar form. \n",
    "## It checks for the on target priming, the uses bowtie2 trimming off the adapter seq. Then exports a bed file for comparing to CRISPRgold\n",
    "\n",
    "\n",
    "### 1. Check reads were correctly primed.\n",
    "### 2. Align the   \n",
    "### 3. Do global end-to-end alignment\n",
    "### 4. process bam file and pull out the high mapQ reads\n",
    "### 5. convert to bed\n",
    "### 6. import bed file as dataframe\n",
    "### 7. check for bed mapping to within 500-1000bp of the predicted cut sites\n",
    "### 8. check if 5' and 3' read both have mappings to the same off target site.\n",
    "\n",
    "We use read1 for checking priming. Also we could use that for mapping (or paired end). On both the 3 and 5' direction the first 34 nucleotides of the read contain the integrated ODN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq2_200924_MN00157_0063_A000H37GTN\n"
     ]
    }
   ],
   "source": [
    "#Directory\n",
    "\n",
    "directory = '/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq2_200924_MN00157_0063_A000H37GTN'\n",
    "\n",
    "#this is a minimal directory of only 300 files for quick debugging\n",
    "#directory = '/Workspace/Spaced_Nicking/GuideSeq_MiniSeq1/10000files'\n",
    "\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard Mispriming Reads\n",
    "When you put a universal primer on the ends of everything, every mispriming event will amplify. An effect we normally don't deal with. I did nested PCR to reduce this. However 85% of the alignments in the UDITAS data I looked at seemed to be mispriming. They did all their blasting and analysis before removing mispriming. But to save computational power and remove error early on I will discard mispriming events. \n",
    "They discard these only for plasmid alignments analyze_alignments_plasmid for some reason which comes from the bam file.\n",
    "\n",
    "### for guideseq read1 is where the ODN primer binds and so that is how you tell targeting. For the reverse it was binidng to the transposon which is random but then the seq primer binds right on it so the the read for read2 begins in the genomic sequence. the Rev primer could misprime but it shouldnt matter as it would then just bind and make smaller amplicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n",
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n",
      "   sample_name    i7    i5  total_reads  reads_with_good_priming  \\\n",
      "0     3GSP_1_1  N701  S506       324260                      199   \n",
      "1     3GSP_1_2  N702  S506       334365                      133   \n",
      "2     3GSP_1_3  N703  S506       309738                      218   \n",
      "3     3GSP_2_1  N704  S506       285699                    86775   \n",
      "4     3GSP_2_2  N705  S506       290166                    78501   \n",
      "5     3GSP_2_3  N706  S506       230665                    74932   \n",
      "6     3GSP_3_1  N707  S506       256615                   145838   \n",
      "7     3GSP_3_2  N710  S506       273500                   159591   \n",
      "8     3GSP_3_3  N711  S506       339570                   190176   \n",
      "9     3GSP_4_1  N712  S506       181289                    50884   \n",
      "10    3GSP_4_2  N714  S506       164237                    88750   \n",
      "11    3GSP_4_3  N715  S506       222801                   110107   \n",
      "12    5GSP_1_1  N701  S507       478510                      526   \n",
      "13    5GSP_1_2  N702  S507       323521                      432   \n",
      "14    5GSP_1_3  N703  S507       360097                      914   \n",
      "15    5GSP_2_1  N704  S507        25585                     1227   \n",
      "16    5GSP_2_2  N705  S507       417265                    56692   \n",
      "17    5GSP_2_3  N706  S507       389590                    49869   \n",
      "18    5GSP_3_1  N707  S507       417061                   189498   \n",
      "19    5GSP_3_2  N710  S507       364885                   182566   \n",
      "20    5GSP_3_3  N711  S507       327124                   168974   \n",
      "21    5GSP_4_1  N712  S507       334509                    30264   \n",
      "22    5GSP_4_2  N714  S507       287589                   132575   \n",
      "23    5GSP_4_3  N715  S507       272564                    77198   \n",
      "\n",
      "    reads_with_guideseq_primer_misprimed  \\\n",
      "0                                  18155   \n",
      "1                                  13253   \n",
      "2                                  19436   \n",
      "3                                  22505   \n",
      "4                                  21260   \n",
      "5                                  26765   \n",
      "6                                  45418   \n",
      "7                                  45905   \n",
      "8                                  65002   \n",
      "9                                  36645   \n",
      "10                                 40361   \n",
      "11                                 44474   \n",
      "12                                  5032   \n",
      "13                                  6354   \n",
      "14                                  6762   \n",
      "15                                  2308   \n",
      "16                                 52289   \n",
      "17                                 53370   \n",
      "18                                 82553   \n",
      "19                                 61599   \n",
      "20                                 40193   \n",
      "21                                 60281   \n",
      "22                                 57339   \n",
      "23                                 57594   \n",
      "\n",
      "    reads_with_indexing_primer_mispriming  \n",
      "0                                  305906  \n",
      "1                                  320979  \n",
      "2                                  290084  \n",
      "3                                  176419  \n",
      "4                                  190405  \n",
      "5                                  128968  \n",
      "6                                   65359  \n",
      "7                                   68004  \n",
      "8                                   84392  \n",
      "9                                   93760  \n",
      "10                                  35126  \n",
      "11                                  68220  \n",
      "12                                 472952  \n",
      "13                                 316735  \n",
      "14                                 352421  \n",
      "15                                  22050  \n",
      "16                                 308284  \n",
      "17                                 286351  \n",
      "18                                 145010  \n",
      "19                                 120720  \n",
      "20                                 117957  \n",
      "21                                 243964  \n",
      "22                                  97675  \n",
      "23                                 137772  \n"
     ]
    }
   ],
   "source": [
    "#the amplicon info is related to the line on the csv file. It is indexed from 0.\n",
    "#it is on my extera space so need to make sure that is mounted. (first thing to check if it throws and error)\n",
    "\n",
    "\n",
    "# THIS IS WHAT RUNS THE PRIMER CHECK THROUGH ALL SAMPLES\n",
    "#input the sample range or list below\n",
    "\n",
    "\n",
    "results_df_all = pd.DataFrame()\n",
    "\n",
    "results_folder = os.path.join(directory, 'results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "results_file = os.path.join(directory, 'results','all_priming.xlsx')\n",
    "    \n",
    "\n",
    "#make results tree\n",
    "\n",
    "for i in range(24):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "\n",
    "    #5primer is everything but AT, AT is for checking mispriming. The full sequence is the olgio from guideseq.\n",
    "    #EVERYTHING IS CAPITAL\n",
    "    guideseq3_seq = 'GTTTAATTGAGTTGTCATATGTTAATAACGGTAT'\n",
    "    guideseq3_primeronly = 'GTTTAATTGAGTTGTCATATGTTAATAACGGT'\n",
    "    #3primer is everything but the final AC. The AC is for checking mispriming\n",
    "    guideseq5_seq = 'ATACCGTTATTAACATATGACAACTCAATTAAAC'\n",
    "    guideseq5_primeronly = 'ATACCGTTATTAACATATGACAACTCAATTAA'\n",
    "\n",
    "    direction = amplicon_info['Direction']\n",
    "\n",
    "    if direction == 3:\n",
    "        primer_seq_plus_downstream = guideseq3_seq\n",
    "        primer_seq = guideseq3_primeronly\n",
    "    elif direction == 5:\n",
    "        primer_seq_plus_downstream = guideseq5_seq\n",
    "        primer_seq = guideseq5_primeronly\n",
    "    \n",
    "    df_sample_results = correct_priming_guideseq(directory, amplicon_info, primer_seq, primer_seq_plus_downstream)\n",
    "    results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "    print('done with sample', i)\n",
    "\n",
    "print(results_df_all)\n",
    "results_df_all.to_excel(results_file)    \n",
    "#print reults to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with sample 0\n",
      "done with sample 1\n",
      "done with sample 2\n",
      "done with sample 3\n",
      "done with sample 4\n",
      "done with sample 5\n",
      "done with sample 6\n",
      "done with sample 7\n",
      "done with sample 8\n",
      "done with sample 9\n",
      "done with sample 10\n",
      "done with sample 11\n",
      "done with sample 12\n",
      "done with sample 13\n",
      "done with sample 14\n",
      "done with sample 15\n",
      "done with sample 16\n",
      "done with sample 17\n",
      "done with sample 18\n",
      "done with sample 19\n",
      "done with sample 20\n",
      "done with sample 21\n",
      "done with sample 22\n",
      "done with sample 23\n"
     ]
    }
   ],
   "source": [
    "### TRIMMING ####\n",
    "#need to trim off the end of the short reads. This is for amplicons that were too short and have the other side on them.\n",
    "\n",
    "for i in range(24):\n",
    "        \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    \n",
    "    trim_guideseq(directory, amplicon_info)\n",
    "    \n",
    "    print('done with sample', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes\n"
     ]
    }
   ],
   "source": [
    "# BOWTIE2_INDEXES are needed for global alignments\n",
    "#check in bash: > ECHO $GENOMES_2BIT\n",
    "%env BOWTIE2_INDEXES=/home/eric/Data/Ref_Genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Need to make an new bowtie2 index file that includes targeting for alignment agains the whole genome so it is all in one sheet together. \n",
    "\n",
    "### Other option would be to align it to the amplicon, extract unaligned files and then align to the genome but seems cleaner this way. \n",
    "#### Ideally every sequence is unique between the targeting vector and genome.\n",
    "\n",
    "\n",
    "1. Build your fastas of interest and label .fa files.\n",
    "    1. You need fasta of hg38 or reference genome. You can pull this from downloaded bowtie indexed sampels and then use the following command to turn the index into a fasta file: bowtie2-inspect hg38 > hg38.fa   \n",
    "    2. Put all the fasta files in the same folder. Should also use the transfected plasmid\n",
    "2. index the files with bowtie\n",
    "    1. use the command bowtie2-build -f pE049,pe038_mc.fa,hg38.fa -p hg38_plus_targetvectorandplasmid\n",
    "    2. this has the -p to make it take less ram in my case.\n",
    "    3. In this case it adds the hg38 and the minicircle targeting file together\n",
    "    4. I have a Intel® Core™ i7-5500U CPU @ 2.40GHz × 4 with 15.1 GiB ram and it required about 13.8 gigs of ram and 2 hours to do a hg38+small fasta index\n",
    "    5. be sure to pay attention to the name of the new indexed file. \"hg38_plus_targetvector\" in example above. Add it to the sample_info.csv sheet. Under the tab 'genome_plus_targeting'.\n",
    "    6. you can check it indexed correcctly: bowtie2-inspect -s hg38_plus_targetvector\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we blast end-to-end the correctly primed sequences.\n",
    "We don't need to trim off anything. But we should remove the length of the ODN primer sequence before blasting for Read1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running row 0\n",
      "the analysis is on Guideseq sample: 3GSP_1_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_1_1  N701  S506                 paired                   149   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                         59  \n",
      "-----  now making bed file for 3GSP_1_1   N701   S506\n",
      "made global bed file: N701 _ S506\n",
      "It is called 3GSP_1_1\n",
      "doing the quantification of global alignments\n",
      "running row 1\n",
      "the analysis is on Guideseq sample: 3GSP_1_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_1_2  N702  S506                 paired                   140   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                         86  \n",
      "-----  now making bed file for 3GSP_1_2   N702   S506\n",
      "made global bed file: N702 _ S506\n",
      "It is called 3GSP_1_2\n",
      "doing the quantification of global alignments\n",
      "running row 2\n",
      "the analysis is on Guideseq sample: 3GSP_1_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_1_3  N703  S506                 paired                   248   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                        129  \n",
      "-----  now making bed file for 3GSP_1_3   N703   S506\n",
      "made global bed file: N703 _ S506\n",
      "It is called 3GSP_1_3\n",
      "doing the quantification of global alignments\n",
      "running row 3\n",
      "the analysis is on Guideseq sample: 3GSP_2_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_2_1  N704  S506                 paired                170166   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     108017  \n",
      "-----  now making bed file for 3GSP_2_1   N704   S506\n",
      "made global bed file: N704 _ S506\n",
      "It is called 3GSP_2_1\n",
      "doing the quantification of global alignments\n",
      "running row 4\n",
      "the analysis is on Guideseq sample: 3GSP_2_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_2_2  N705  S506                 paired                140617   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      95796  \n",
      "-----  now making bed file for 3GSP_2_2   N705   S506\n",
      "made global bed file: N705 _ S506\n",
      "It is called 3GSP_2_2\n",
      "doing the quantification of global alignments\n",
      "running row 5\n",
      "the analysis is on Guideseq sample: 3GSP_2_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_2_3  N706  S506                 paired                181195   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      95520  \n",
      "-----  now making bed file for 3GSP_2_3   N706   S506\n",
      "made global bed file: N706 _ S506\n",
      "It is called 3GSP_2_3\n",
      "doing the quantification of global alignments\n",
      "running row 6\n",
      "the analysis is on Guideseq sample: 3GSP_3_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_3_1  N707  S506                 paired                361876   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     206762  \n",
      "-----  now making bed file for 3GSP_3_1   N707   S506\n",
      "made global bed file: N707 _ S506\n",
      "It is called 3GSP_3_1\n",
      "doing the quantification of global alignments\n",
      "running row 7\n",
      "the analysis is on Guideseq sample: 3GSP_3_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_3_2  N710  S506                 paired                395820   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     225123  \n",
      "-----  now making bed file for 3GSP_3_2   N710   S506\n",
      "made global bed file: N710 _ S506\n",
      "It is called 3GSP_3_2\n",
      "doing the quantification of global alignments\n",
      "running row 8\n",
      "the analysis is on Guideseq sample: 3GSP_3_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_3_3  N711  S506                 paired                446250   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     298057  \n",
      "-----  now making bed file for 3GSP_3_3   N711   S506\n",
      "made global bed file: N711 _ S506\n",
      "It is called 3GSP_3_3\n",
      "doing the quantification of global alignments\n",
      "running row 9\n",
      "the analysis is on Guideseq sample: 3GSP_4_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_4_1  N712  S506                 paired                116570   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      83015  \n",
      "-----  now making bed file for 3GSP_4_1   N712   S506\n",
      "made global bed file: N712 _ S506\n",
      "It is called 3GSP_4_1\n",
      "doing the quantification of global alignments\n",
      "running row 10\n",
      "the analysis is on Guideseq sample: 3GSP_4_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_4_2  N714  S506                 paired                277561   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     133092  \n",
      "-----  now making bed file for 3GSP_4_2   N714   S506\n",
      "made global bed file: N714 _ S506\n",
      "It is called 3GSP_4_2\n",
      "doing the quantification of global alignments\n",
      "running row 11\n",
      "the analysis is on Guideseq sample: 3GSP_4_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    3GSP_4_3  N715  S506                 paired                278295   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     186927  \n",
      "-----  now making bed file for 3GSP_4_3   N715   S506\n",
      "made global bed file: N715 _ S506\n",
      "It is called 3GSP_4_3\n",
      "doing the quantification of global alignments\n",
      "running row 12\n",
      "the analysis is on Guideseq sample: 5GSP_1_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_1_1  N701  S507                 paired                   763   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                        238  \n",
      "-----  now making bed file for 5GSP_1_1   N701   S507\n",
      "made global bed file: N701 _ S507\n",
      "It is called 5GSP_1_1\n",
      "doing the quantification of global alignments\n",
      "running row 13\n",
      "the analysis is on Guideseq sample: 5GSP_1_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_1_2  N702  S507                 paired                   834   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                        230  \n",
      "-----  now making bed file for 5GSP_1_2   N702   S507\n",
      "made global bed file: N702 _ S507\n",
      "It is called 5GSP_1_2\n",
      "doing the quantification of global alignments\n",
      "running row 14\n",
      "the analysis is on Guideseq sample: 5GSP_1_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_1_3  N703  S507                 paired                  2253   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                        966  \n",
      "-----  now making bed file for 5GSP_1_3   N703   S507\n",
      "made global bed file: N703 _ S507\n",
      "It is called 5GSP_1_3\n",
      "doing the quantification of global alignments\n",
      "running row 15\n",
      "the analysis is on Guideseq sample: 5GSP_2_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_2_1  N704  S507                 paired                  3303   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                       1425  \n",
      "-----  now making bed file for 5GSP_2_1   N704   S507\n",
      "made global bed file: N704 _ S507\n",
      "It is called 5GSP_2_1\n",
      "doing the quantification of global alignments\n",
      "running row 16\n",
      "the analysis is on Guideseq sample: 5GSP_2_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_2_2  N705  S507                 paired                119957   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      87373  \n",
      "-----  now making bed file for 5GSP_2_2   N705   S507\n",
      "made global bed file: N705 _ S507\n",
      "It is called 5GSP_2_2\n",
      "doing the quantification of global alignments\n",
      "running row 17\n",
      "the analysis is on Guideseq sample: 5GSP_2_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_2_3  N706  S507                 paired                 87860   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      73479  \n",
      "-----  now making bed file for 5GSP_2_3   N706   S507\n",
      "made global bed file: N706 _ S507\n",
      "It is called 5GSP_2_3\n",
      "doing the quantification of global alignments\n",
      "running row 18\n",
      "the analysis is on Guideseq sample: 5GSP_3_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_3_1  N707  S507                 paired                506141   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     284771  \n",
      "-----  now making bed file for 5GSP_3_1   N707   S507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made global bed file: N707 _ S507\n",
      "It is called 5GSP_3_1\n",
      "doing the quantification of global alignments\n",
      "running row 19\n",
      "the analysis is on Guideseq sample: 5GSP_3_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_3_2  N710  S507                 paired                494741   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     286633  \n",
      "-----  now making bed file for 5GSP_3_2   N710   S507\n",
      "made global bed file: N710 _ S507\n",
      "It is called 5GSP_3_2\n",
      "doing the quantification of global alignments\n",
      "running row 20\n",
      "the analysis is on Guideseq sample: 5GSP_3_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_3_3  N711  S507                 paired                405303   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     265740  \n",
      "-----  now making bed file for 5GSP_3_3   N711   S507\n",
      "made global bed file: N711 _ S507\n",
      "It is called 5GSP_3_3\n",
      "doing the quantification of global alignments\n",
      "running row 21\n",
      "the analysis is on Guideseq sample: 5GSP_4_1\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_4_1  N712  S507                 paired                 90010   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      30274  \n",
      "-----  now making bed file for 5GSP_4_1   N712   S507\n",
      "made global bed file: N712 _ S507\n",
      "It is called 5GSP_4_1\n",
      "doing the quantification of global alignments\n",
      "running row 22\n",
      "the analysis is on Guideseq sample: 5GSP_4_2\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_4_2  N714  S507                 paired                391217   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                     186860  \n",
      "-----  now making bed file for 5GSP_4_2   N714   S507\n",
      "made global bed file: N714 _ S507\n",
      "It is called 5GSP_4_2\n",
      "doing the quantification of global alignments\n",
      "running row 23\n",
      "the analysis is on Guideseq sample: 5GSP_4_3\n",
      "single por paired paired\n",
      "  sample_name    i7    i5 single_or_paired_reads  all_alignments_count  \\\n",
      "0    5GSP_4_3  N715  S507                 paired                184033   \n",
      "\n",
      "   filtered_alignments_count  \n",
      "0                      98354  \n",
      "-----  now making bed file for 5GSP_4_3   N715   S507\n",
      "made global bed file: N715 _ S507\n",
      "It is called 5GSP_4_3\n",
      "doing the quantification of global alignments\n"
     ]
    }
   ],
   "source": [
    "### This section does two things. It makes a bam file that is filtered for AS and MAPQ \n",
    "#   It quantifies these bam files and sorts them. Then it converts to a bed file.\n",
    "#\n",
    "\n",
    "#### Required Arguments\n",
    "cpu = 12\n",
    "min_MAPQ = 50\n",
    "min_AS = -180\n",
    "\n",
    "### WHAT TYPE OF ANALYSIS ARE WE RUNNING\n",
    "#####type in 'on' or 'off'\n",
    "local = 'off' #local is softclipped NEED TO MAKE THIS TO USE IT\n",
    "global_align_branch = 'on' #global is end-to-end and this does the analysis\n",
    "#this does the acutal alignment for end-to-end\n",
    "do_align_global = 'on'\n",
    "single_or_paired_reads = \"paired\"  #can be 'single' or 'paired' for the read alignment\n",
    "\n",
    "#### WHAT SAMPLES TO RUN ####\n",
    "#lines_to_run = [20]\n",
    "lines_to_run = range(24)\n",
    "\n",
    "#for exporting summary of data\n",
    "results_df_all = pd.DataFrame()\n",
    "results_file = os.path.join(directory, 'results','alignment_filtered_summary.xlsx')\n",
    "\n",
    "\n",
    "for i in lines_to_run:\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    print('running row', i)\n",
    "    print('the analysis is on Guideseq sample:', amplicon_info['name'])\n",
    "    reference_assembly = amplicon_info['genome']\n",
    "    sample_name = amplicon_info['name']\n",
    "    \n",
    "    if global_align_branch == 'on':\n",
    "        if do_align_global == 'on':\n",
    "            #####this aligns everything after the break to end-to-end keep_sam=1 means keep the sam file\n",
    "            align_guideseq_end_to_end_genome_global(directory, amplicon_info, reference_assembly, single_or_paired_reads, cpu, keep_sam=1)\n",
    "\n",
    "            \n",
    "        #### Process the alignment files to make a bam file of only high quality reads\n",
    "        \n",
    "        #this filters for good alignments based on AS score and MapQ and exports a final indexed bam file.\n",
    "\n",
    "        df_sample_results = guideseq_filtered_mapq_AS_primary(directory, 'global', amplicon_info, single_or_paired_reads)\n",
    "        #this is a running dataframe of the clenaed up read summary\n",
    "        results_df_all = results_df_all.append(df_sample_results, ignore_index=True)\n",
    "        \n",
    "        \n",
    "        ### global alignment bed generation \n",
    "        N7 = amplicon_info['index_I1']\n",
    "        N5 = amplicon_info['index_I2']\n",
    "        print('-----  now making bed file for', sample_name, ' ',N7, ' ', N5 )\n",
    "        \n",
    "        \n",
    "        ##### Need to fix this!!!!!!!!!!!! the names of the input are not right and mabye i need to sort things\n",
    "        if single_or_paired_reads == \"single\":\n",
    "            genome_global_bed_file = create_filename(directory, N7, N5, 'guideseq_global_bed_single')\n",
    "            filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_global_single')\n",
    "        elif single_or_paired_reads == \"paired\":\n",
    "            genome_global_bed_file = create_filename(directory, N7, N5, 'guideseq_global_bed_paired')\n",
    "            filtered_and_sorted_bam_file = create_filename(directory, N7, N5, 'filtered_and_sorted_genome_global_paired')\n",
    "    \n",
    "        !bam2bed < {filtered_and_sorted_bam_file} > {genome_global_bed_file}\n",
    "        bed_folder = os.path.join(directory, 'bed_files')\n",
    "\n",
    "        if not os.path.exists(bed_folder):\n",
    "            os.mkdir(bed_folder)\n",
    "        \n",
    "        file_location = create_filename(directory, N7, N5, 'bam_global')\n",
    "        \n",
    "        new_bed_name = os.path.join(file_location, sample_name + '_' + single_or_paired_reads + '.bed')\n",
    "\n",
    "        os.rename(genome_global_bed_file, new_bed_name)\n",
    "\n",
    "        shutil.copy(new_bed_name, bed_folder)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        print('made global bed file:', N7, '_', N5 )\n",
    "        print('It is called',sample_name )\n",
    "        print('doing the quantification of global alignments')\n",
    "\n",
    " \n",
    "    \n",
    "    ########### I don't use local so ignore this #############\n",
    "    if local == 'on':\n",
    "        #### this aligns everything in the local format wehre it can soft clip the ends keep_sam=1 means keep the sam file\n",
    "        # need to make this section if I want to use it\n",
    "        align_afterbreaks_genome_local(directory, 1, amplicon_info, assembly_plus_targetvector, lam_or_tn5='lam', keep_sam=0)\n",
    "        \n",
    "        #make bed file\n",
    "        print('-----  now making bed file   ------')\n",
    "        N7 = amplicon_info['index_I1']\n",
    "        N5 = amplicon_info['index_I2']\n",
    "        file_trimmed_genome_local_bed = create_filename(directory, N7, N5, 'break_trimmed_genome_local_bed')\n",
    "        file_sorted_bam_genome_local = create_filename(directory, N7, N5, 'break_trimmed_filtered_and_sorted_bam_genome_local')\n",
    "\n",
    "        !bam2bed < {file_sorted_bam_genome_local} > {file_trimmed_genome_local_bed}\n",
    "        bed_folder = os.path.join(directory, 'bed_files')\n",
    "        \n",
    "        if not os.path.exists(bed_folder):\n",
    "            os.mkdir(bed_folder)\n",
    "        shutil.copy(file_trimmed_genome_local_bed, bed_folder)\n",
    "    \n",
    "        \n",
    "        print('made local bed file:', N7, '_', N5 )\n",
    "\n",
    "        # running overview of alignment quantification\n",
    "        print('doing the quantification of local alignments')\n",
    "        quantify_local = quantify_pipeline2_alignments(directory, 'local', amplicon_info, 'lam')\n",
    "        print(quantify_local)\n",
    "\n",
    "#export all the read summaries\n",
    "results_df_all.to_excel(results_file)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listnumber2                 object\n",
      "Sequence                    object\n",
      "Name                        object\n",
      "Top off-target sites        object\n",
      "Strand                      object\n",
      "MutDist                      int64\n",
      "Risk                        object\n",
      "Annotation (if relevant)    object\n",
      "chr                         object\n",
      "position_start               int64\n",
      "position_end                object\n",
      "begin_site_range             int64\n",
      "end_site_range               int64\n",
      "dtype: object\n",
      "running row 1\n",
      "the analysis is on Guideseq sample: 2-1-3'GSP-TD\n",
      "index\n",
      "index N702 S502\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/results/N702_S502_2-1-3'GSP-TD_guide_count.xlsx\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/N702_S502/bam_genome_global_files\n",
      "/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/N702_S502/bam_genome_global_files/2-1-3'GSP-TD_paired.bed\n",
      "chr                     object\n",
      "chromStart               int64\n",
      "chromEnd                 int64\n",
      "name                    object\n",
      "MapQ                     int64\n",
      "strand                  object\n",
      "flag                     int64\n",
      "CIGAR                   object\n",
      "paired_name             object\n",
      "read1start               int64\n",
      "paired_amplicon_size     int64\n",
      "sequence                object\n",
      "quality_score           object\n",
      "a                       object\n",
      "b                       object\n",
      "c                       object\n",
      "d                       object\n",
      "e                       object\n",
      "f                       object\n",
      "g                       object\n",
      "h                       object\n",
      "i                       object\n",
      "dtype: object\n",
      "list of read hits: [1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "############ Use CIRPSR Gold and look at overlaps\n",
    "\n",
    "single_or_paired_reads = \"paired\"  #can be 'single' or 'paired' for the read alignment\n",
    "windowsize = 500\n",
    "\n",
    "#### WHAT SAMPLES TO RUN ####\n",
    "lines_to_run = [1]\n",
    "#lines_to_run = range(30)\n",
    "\n",
    "\n",
    "#off_target_sites \n",
    "crispr_gold_file = '/home/eric/Data/Spaced_Nicking/GuideSeq_MiniSeq1/CrispRgold_predictions.xlsx'\n",
    "df_targets = pd.read_excel(crispr_gold_file, index_col=0)\n",
    "\n",
    "# new data frame with split guide location. CRISPRGOLD puts it all in at once\n",
    "new = df_targets[\"Position\"].str.split(\":\", expand = True) \n",
    "df_targets[\"chr\"]= new[0] \n",
    "df_targets[\"position_start\"]= new[1] \n",
    "df_targets[\"position_end\"]= new[2] \n",
    "df_targets.drop(columns =[\"Position\"], inplace = True) \n",
    "df_targets['position_start'] = df_targets['position_start'].astype(int)\n",
    "df_targets['begin_site_range'] = df_targets['position_start'] - windowsize\n",
    "df_targets['end_site_range'] = df_targets['position_start'] + windowsize\n",
    "\n",
    "print(df_targets.dtypes)\n",
    "\n",
    "#print(df_targets)\n",
    "\n",
    "\n",
    "for i in lines_to_run:\n",
    "    \n",
    "    amplicon_info = get_csv_data(directory, i)\n",
    "    name = amplicon_info['name']\n",
    "    print('running row', i)\n",
    "    print('the analysis is on Guideseq sample:', name)\n",
    "    print('index',)\n",
    "    \n",
    "    #import bed file\n",
    "    N7 = amplicon_info['index_I1']\n",
    "    N5 = amplicon_info['index_I2']\n",
    "    print('index', N7, N5)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(results_file)\n",
    "\n",
    "    file_location = create_filename(directory, N7, N5, 'bam_global')   \n",
    "    print(file_location)\n",
    "    sample_name = amplicon_info['name']\n",
    "    bedfile = os.path.join(file_location, sample_name + '_' + single_or_paired_reads + '.bed')\n",
    "    print(bedfile)\n",
    "    \n",
    "    #needs to add header names to specify the number of columns so that \n",
    "    \n",
    "    header_names = ['chr', 'chromStart', 'chromEnd', 'name', 'MapQ', 'strand', 'flag', 'CIGAR', 'paired_name', 'read1start', 'paired_amplicon_size', 'sequence', 'quality_score','a','b','c','d','e','f','g','h','i']\n",
    "\n",
    "#    df_bed = pd.read_csv(bedfile, sep='\\t', comment='t', header=None)\n",
    "    df_bed = pd.read_csv(bedfile, sep='\\t', header=None, names = header_names)\n",
    "\n",
    "    \n",
    "    \n",
    "    #header = ['chr', 'chromStart', 'chromEnd', 'name', 'MapQ', 'strand', 'flag', 'CIGAR', 'paired_name', 'read1start', 'paired_amplicon_size', 'sequence', 'quality_score','a','b','c','d','e','f','g','h','i']\n",
    "    #df_bed.columns = header[:len(df_bed.columns)]\n",
    "    \n",
    "    print(df_bed.dtypes) \n",
    "    \n",
    "    read_hits = []\n",
    "    count = 0\n",
    "    for i,g in itertools.izip(df_bed.chromStart, df_bed.chr):\n",
    "        bed_alignment = i\n",
    "        chromosome = g\n",
    "        for a,b,c,d in itertools.izip(df_targets.listnumber2, df_targets.begin_site_range, df_targets.end_site_range, df_targets.chr): \n",
    "            counter_A = 0\n",
    "            if bed_alignment in range(b, c) and chromosome == d:\n",
    "                if counter = 0:\n",
    "                    print(b,c,'chromosome', d, ' guide:', a)\n",
    "                    read_hits.append(a)\n",
    "                    counter_A += 1\n",
    "                    print(b,c,'chromosome', d, ' guide:', a, 'for read starting at :', i)\n",
    "        count += 1 \n",
    "        if count >30:\n",
    "            break\n",
    "    results_df = pd.DataFrame({'sample_name': [name],\n",
    "                               'i7': [N7],\n",
    "                               'i5': [N5],\n",
    "                               'list_of_read_guide_matches' : [read_hits],\n",
    "                               },\n",
    "                                  columns=['sample_name',\n",
    "                                           'i7',\n",
    "                                           'i5',\n",
    "                                           'list_of_read_guide_matches'])            \n",
    "    \n",
    "    \n",
    "    \n",
    "    results_file = os.path.join(directory, 'results',N7 + '_' + N5 + '_'+ name +'_guide_count.xlsx')\n",
    "    \n",
    "    results_df.to_excel(results_file)    \n",
    "\n",
    "    print('list of read hits:',read_hits)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
